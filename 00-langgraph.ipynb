{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 핸즈온\n",
    "\n",
    "**참고하면 좋은 자료**\n",
    "\n",
    "- [LangChain 한국어 튜토리얼🇰🇷](https://wikidocs.net/book/14314)\n",
    "- [LangChain 한국어 튜토리얼 Github 소스코드](https://github.com/teddylee777/langchain-kr)\n",
    "- [테디노트 YouTube](https://www.youtube.com/c/@teddynote)\n",
    "- [테디노트 블로그](https://teddylee777.github.io/)\n",
    "- [테디노트 YouTube 로 RAG 배우기!](https://teddylee777.notion.site/YouTube-RAG-10a24f35d12980dc8478c750faa752a2?pvs=74)\n",
    "- [RAG 비법노트](https://fastcampus.co.kr/data_online_teddy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. 환경 설정\n",
    "\n",
    "**OpenAI API Key 설정**\n",
    "- https://wikidocs.net/233342\n",
    "\n",
    "**웹 검색을 위한 API 키 발급 주소**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "회원 가입 후 API Key를 발급합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**설치를 진행합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: langchain_openai in /Users/kb/repos/venv/lib/python3.12/site-packages (0.1.23)\n",
      "Collecting langchain_teddynote\n",
      "  Downloading langchain_teddynote-0.3.42-py3-none-any.whl.metadata (708 bytes)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: langchain_community in /Users/kb/repos/venv/lib/python3.12/site-packages (0.2.15)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langgraph) (0.2.37)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_openai) (1.40.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: langchain in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_teddynote) (0.2.15)\n",
      "Collecting kiwipiepy (from langchain_teddynote)\n",
      "  Downloading kiwipiepy-0.20.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.1 kB)\n",
      "Collecting rank-bm25 (from langchain_teddynote)\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pinecone-client[grpc] (from langchain_teddynote)\n",
      "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pinecone-text (from langchain_teddynote)\n",
      "  Downloading pinecone_text-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting olefile (from langchain_teddynote)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting pdf2image (from langchain_teddynote)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting anthropic (from langchain_teddynote)\n",
      "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting deepl (from langchain_teddynote)\n",
      "  Downloading deepl-1.21.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting feedparser (from langchain_teddynote)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tavily-python (from langchain_teddynote)\n",
      "  Downloading tavily_python-0.5.1-py3-none-any.whl.metadata (91 kB)\n",
      "Collecting pandas (from langchain_teddynote)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/kb/repos/venv/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20231228->pdfplumber)\n",
      "  Downloading cryptography-44.0.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_community) (3.10.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_community) (0.1.98)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kb/repos/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kb/repos/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain->langchain_teddynote) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain->langchain_teddynote) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
      "Collecting langchain-core<0.4,>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/kb/repos/venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kb/repos/venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kb/repos/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kb/repos/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kb/repos/venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.7.24)\n",
      "Collecting sgmllib3k (from feedparser->langchain_teddynote)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kiwipiepy_model<0.21,>=0.20 (from kiwipiepy->langchain_teddynote)\n",
      "  Downloading kiwipiepy_model-0.20.0.tar.gz (34.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/kb/repos/venv/lib/python3.12/site-packages (from pandas->langchain_teddynote) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from pandas->langchain_teddynote) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas->langchain_teddynote)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting googleapis-common-protos>=1.66.0 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting grpcio>=1.59.0 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting lz4>=3.1.3 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading lz4-4.4.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting protobuf<6.0,>=5.29 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting protoc-gen-openapiv2<0.0.2,>=0.0.1 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3<5.0.0,>=4.1.0 (from pinecone-text->langchain_teddynote)\n",
      "  Downloading mmh3-4.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting nltk<4.0.0,>=3.6.5 (from pinecone-text->langchain_teddynote)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from pinecone-text->langchain_teddynote) (1.0.1)\n",
      "Collecting types-requests<3.0.0,>=2.25.0 (from pinecone-text->langchain_teddynote)\n",
      "  Downloading types_requests-2.32.0.20250301-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting wget<4.0,>=3.2 (from pinecone-text->langchain_teddynote)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /Users/kb/repos/venv/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kb/repos/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kb/repos/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kb/repos/venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
      "Collecting click (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain_teddynote)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain_teddynote)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain->langchain_teddynote) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/kb/repos/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain->langchain_teddynote) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kb/repos/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->langchain_teddynote) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kb/repos/venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/kb/repos/venv/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading langgraph-0.3.2-py3-none-any.whl (130 kB)\n",
      "Downloading langchain_teddynote-0.3.42-py3-none-any.whl (51 kB)\n",
      "Downloading faiss_cpu-1.10.0-cp312-cp312-macosx_11_0_arm64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
      "Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl (24 kB)\n",
      "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
      "Downloading deepl-1.21.0-py3-none-any.whl (38 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading kiwipiepy-0.20.3-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pinecone_text-0.9.0-py3-none-any.whl (23 kB)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading tavily_python-0.5.1-py3-none-any.whl (43 kB)\n",
      "Downloading cryptography-44.0.1-cp39-abi3-macosx_10_9_universal2.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl (164 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-macosx_10_14_universal2.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lz4-4.4.3-cp312-cp312-macosx_11_0_arm64.whl (189 kB)\n",
      "Downloading mmh3-4.1.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl (82 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl (7.9 kB)\n",
      "Downloading types_requests-2.32.0.20250301-py3-none-any.whl (20 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Building wheels for collected packages: kiwipiepy_model, wget, sgmllib3k\n",
      "  Building wheel for kiwipiepy_model (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.20.0-py3-none-any.whl size=34818071 sha256=2fc3b731548385572fbdd44285346f42012bd259cf7585bf97d1da480226073d\n",
      "  Stored in directory: /Users/kb/Library/Caches/pip/wheels/f3/14/24/bd3e0c3aa06df12afcb35447b07840213644855333f33bfce5\n",
      "  Building wheel for wget (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9685 sha256=d143c62aac61acc49ca8de858db0b37280fd556946d1d72a35e6b8be70db855b\n",
      "  Stored in directory: /Users/kb/Library/Caches/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "  Building wheel for sgmllib3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6090 sha256=7bb3cd9da8bf29a63852679a8be87dd6fd838fb9a8061fdbeb9a00d13b2f831e\n",
      "  Stored in directory: /Users/kb/Library/Caches/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built kiwipiepy_model wget sgmllib3k\n",
      "Installing collected packages: wget, sgmllib3k, mmh3, kiwipiepy_model, tzdata, types-requests, rank-bm25, pypdfium2, protobuf, pinecone-plugin-interface, pdf2image, olefile, msgpack, lz4, kiwipiepy, joblib, grpcio, feedparser, faiss-cpu, click, pinecone-client, pandas, nltk, googleapis-common-protos, deepl, cryptography, tavily-python, protoc-gen-openapiv2, pinecone-text, pdfminer.six, langsmith, langgraph-sdk, anthropic, pdfplumber, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain_teddynote\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.8\n",
      "    Uninstalling msgpack-1.0.8:\n",
      "      Successfully uninstalled msgpack-1.0.8\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.98\n",
      "    Uninstalling langsmith-0.1.98:\n",
      "      Successfully uninstalled langsmith-0.1.98\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.37\n",
      "    Uninstalling langchain-core-0.2.37:\n",
      "      Successfully uninstalled langchain-core-0.2.37\n",
      "Successfully installed anthropic-0.49.0 click-8.1.8 cryptography-44.0.1 deepl-1.21.0 faiss-cpu-1.10.0 feedparser-6.0.11 googleapis-common-protos-1.68.0 grpcio-1.70.0 joblib-1.4.2 kiwipiepy-0.20.3 kiwipiepy_model-0.20.0 langchain-core-0.2.43 langchain_teddynote-0.3.42 langgraph-0.3.2 langgraph-checkpoint-2.0.16 langgraph-prebuilt-0.1.1 langgraph-sdk-0.1.53 langsmith-0.1.147 lz4-4.4.3 mmh3-4.1.0 msgpack-1.1.0 nltk-3.9.1 olefile-0.47 pandas-2.2.3 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.5 pinecone-client-6.0.0 pinecone-plugin-interface-0.0.7 pinecone-text-0.9.0 protobuf-5.29.3 protoc-gen-openapiv2-0.0.1 pypdfium2-4.30.1 rank-bm25-0.2.2 sgmllib3k-1.0.0 tavily-python-0.5.1 types-requests-2.32.0.20250301 tzdata-2025.1 wget-3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain_openai langchain_teddynote faiss-cpu pdfplumber langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습자료를 다운로드 받습니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /Users/kb/repos/langcon-2025-handson\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"현재 작업 디렉토리: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드할 .env 파일 경로: /Users/kb/repos/langcon-2025-handson/rag/.env\n",
      ".env 파일이 존재합니다!\n",
      "OpenAI API Key: sk-pr...YuMA\n",
      "OpenAI API Key 길이: 164자\n",
      "Tavily API Key: tvly-de...IAFM\n",
      "Tavily API Key 길이: 41자\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일의 정확한 경로 지정\n",
    "env_path = os.path.join(os.getcwd(), 'rag', '.env')\n",
    "print(f\"로드할 .env 파일 경로: {env_path}\")\n",
    "\n",
    "# .env 파일 존재 여부 확인\n",
    "if os.path.exists(env_path):\n",
    "    print(\".env 파일이 존재합니다!\")\n",
    "    \n",
    "    # .env 파일에서 환경 변수 로드\n",
    "    load_dotenv(dotenv_path=env_path, override=True)\n",
    "    \n",
    "    # 환경 변수 확인\n",
    "    openai_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    tavily_key = os.environ.get(\"TAVILY_API_KEY\", \"\")\n",
    "    \n",
    "    if openai_key:\n",
    "        print(f\"OpenAI API Key: {openai_key[:5]}...{openai_key[-4:] if len(openai_key) > 4 else ''}\")\n",
    "        print(f\"OpenAI API Key 길이: {len(openai_key)}자\")\n",
    "    else:\n",
    "        print(\"OpenAI API Key가 설정되지 않았습니다.\")\n",
    "    \n",
    "    if tavily_key:\n",
    "        print(f\"Tavily API Key: {tavily_key[:7]}...{tavily_key[-4:] if len(tavily_key) > 4 else ''}\")\n",
    "        print(f\"Tavily API Key 길이: {len(tavily_key)}자\")\n",
    "    else:\n",
    "        print(\"Tavily API Key가 설정되지 않았습니다.\")\n",
    "else:\n",
    "    print(f\".env 파일이 지정한 경로에 존재하지 않습니다: {env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"  # 발급 받은 OpenAI API Key 입력\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"\"  # 발급 받은 Tavily API Key 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(선택 사항)\n",
    "\n",
    "LangSmith 추적을 원하는 경우 아래 LangSmith API Key 를 발급 받아 입력해 주세요.\n",
    "\n",
    "- 링크: https://smith.langchain.com\n",
    "- 회원 가입 후 - 설정 - 상단 API Keys 에서 발급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_API_KEY\"] = \"\"  # 발급 받은 LangSmith API Key 입력\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # 추적 설정\n",
    "# os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"  # 추적 엔드포인트\n",
    "# os.environ[\"LANGSMITH_PROJECT\"] = \"LangGraph-Hands-On\"  # 프로젝트 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. 기본 ReAct Agent 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 설정\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도구 (Tools) 설정\n",
    "\n",
    "도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스입니다.\n",
    "\n",
    "LangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능합니다.\n",
    "\n",
    "**LangChain 에 통합된 도구 리스트는 아래 링크에서 확인할 수 있습니다.**\n",
    "\n",
    "랭체인에서 제공하는 사전에 정의된 도구(tool) 와 툴킷(toolkit) 을 사용할 수 있습니다.\n",
    "\n",
    "tool 은 단일 도구를 의미하며, toolkit 은 여러 도구를 묶어서 하나의 도구로 사용할 수 있습니다.\n",
    "\n",
    "관련 도구는 아래의 링크에서 참고하실 수 있습니다.\n",
    "\n",
    "**참고**\n",
    "- [LangChain Tools/Toolkits](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**검색 API 도구**\n",
    "\n",
    "Tavily 검색 API를 활용하여 검색 기능을 구현하는 도구입니다. \n",
    "\n",
    "**API 키 발급 주소**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "발급한 API 키를 환경변수에 설정합니다.\n",
    "\n",
    "`.env` 파일에 아래와 같이 설정합니다.\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n",
    "```\n",
    "\n",
    "**TavilySearch**\n",
    "\n",
    "**설명**\n",
    "- Tavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환합니다.\n",
    "- 포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진입니다.\n",
    "- 현재 이벤트에 대한 질문에 답변할 때 유용합니다.\n",
    "\n",
    "**주요 매개변수**\n",
    "- `max_results` (int): 반환할 최대 검색 결과 수 (기본값: 5)\n",
    "- `search_depth` (str): 검색 깊이 (\"basic\" 또는 \"advanced\")\n",
    "- `include_domains` (List[str]): 검색 결과에 포함할 도메인 목록\n",
    "- `exclude_domains` (List[str]): 검색 결과에서 제외할 도메인 목록\n",
    "- `include_answer` (bool): 원본 쿼리에 대한 짧은 답변 포함 여부\n",
    "- `include_raw_content` (bool): 각 사이트의 정제된 HTML 콘텐츠 포함 여부\n",
    "- `include_images` (bool): 쿼리 관련 이미지 목록 포함 여부\n",
    "\n",
    "**반환 값**\n",
    "- 검색 결과를 포함하는 JSON 형식의 문자열(url, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 웹 검색 도구를 설정합니다.\n",
    "web_search_tool = TavilySearch(\n",
    "    max_results=6,  # 최대 검색 결과\n",
    ")\n",
    "\n",
    "# 웹 검색 도구의 이름과 설명을 설정합니다.  매우 중요함. 어떤 도구를 쓸지 AI가 알려줘야함. \n",
    "web_search_tool.name = \"web_search\"\n",
    "web_search_tool.description = \"Use this tool to search on the web\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PDFRetrievalChain`: PDF 문서 기반 Naive RAG 체인\n",
    "\n",
    "문서 기반 RAG 체인을 생성합니다. 이 체인은 주어진 PDF 문서를 기반으로 검색 기능을 제공합니다.\n",
    "\n",
    "**주요 매개변수**\n",
    "- `source_uri` (List[str]): PDF 문서의 경로\n",
    "- `model_name` (str): 사용할 모델의 이름\n",
    "- `k` (int): 반환할 최대 검색 결과 수 (기본값: 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain(\n",
    "    [\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"], model_name=\"gpt-4o-mini\", k=6\n",
    ").create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\\n▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\\n▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='<구글 딥마인드의 범용 AI 분류 프레임워크>\\n성능 특수 AI 예시 범용 AI 예시\\n0단계: AI 아님 계산기 소프트웨어, 컴파일러 아마존 메커니컬 터크\\n1단계: 신진(숙련되지 않은 인간) GOFAI(Good Old Fashioned Artificial Intelligence) 챗GPT, 바드, 라마2\\n스마트 스피커(애플 시리, 아마존 알렉사, 구글\\n2단계: 유능(숙련된 인간의 50% 이상) 미달성\\n어시스턴트), IBM 왓슨\\n3단계: 전문가(숙련된 인간의 90% 이상) 문법 교정기(그래머리), 생성 이미지 모델(달리2) 미달성'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: Connection error caused failure to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. Please confirm your internet connection. SSLError(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs/multipart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2406)')))\"))\n",
      "Content-Length: 595009\n",
      "API Key: lsv2_**********..trace=c5a40433-51b2-455a-a7b2-c6039ece7580,id=5e10562a-cce0-42a2-994d-91dd3f2647cd; trace=c5a40433-51b2-455a-a7b2-c6039ece7580,id=66d03d07-c344-48c8-8c5e-8470ce15d84b; trace=c5a40433-51b2-455a-a7b2-c6039ece7580,id=a2cd8c94-b968-4d69-b09f-11d302acb302; trace=c5a40433-51b2-455a-a7b2-c6039ece7580,id=6f80fbec-2995-4fa0-b47a-feaaf0c07b05; trace=c5a40433-51b2-455a-a7b2-c6039ece7580,id=4d40003a-e9bb-416b-8e04-168c9a58d978; trace=c5a40433-51b2-455a-a7b2-c6039ece7580,id=ffb0f03a-135d-448e-bbcd-95accbdcf7f8; trace=c5a40433-51b2-455a-a7b2-c6039ece7580,id=c5a40433-51b2-455a-a7b2-c6039ece7580\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# 검색 쿼리를 입력하여 검색 결과를 반환합니다.\n",
    "searched_docs = pdf_retriever.invoke(\"삼성전자가 만든 생성형 AI 이름을 찾아줘\")\n",
    "searched_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**추적**: https://smith.langchain.com/public/bdaa2410-0a6a-44c9-8e2b-c5d8628bf84e/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자가 만든 생성형 AI의 이름은 '삼성 가우스'입니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 1)\n"
     ]
    }
   ],
   "source": [
    "answer = pdf_chain.invoke(\n",
    "    {\"question\": \"삼성전자가 만든 생성형 AI 이름을 찾아줘\", \"context\": searched_docs}\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "# PDF 문서를 기반으로 검색 도구 생성\n",
    "# 여기서도 llm 이 도구를 찾기 때문에 이름이랑 도구 목적을 반드시 상세히 적어줘야함. \n",
    "retriever_tool = create_retriever_tool( \n",
    "    pdf_retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"Search and return information about SPRI AI Brief PDF file. It contains useful information on recent AI trends. The document is published on Dec 2023.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "\n",
      "SPRi AI Brief |\n",
      "2023-12월호\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "KEY Contents\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "\n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "10\n",
      "\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "\n",
      "<구글 딥마인드의 범용 AI 분류 프레임워크>\n",
      "성능 특수 AI 예시 범용 AI 예시\n",
      "0단계: AI 아님 계산기 소프트웨어, 컴파일러 아마존 메커니컬 터크\n",
      "1단계: 신진(숙련되지 않은 인간) GOFAI(Good Old Fashioned Artificial Intelligence) 챗GPT, 바드, 라마2\n",
      "스마트 스피커(애플 시리, 아마존 알렉사, 구글\n",
      "2단계: 유능(숙련된 인간의 50% 이상) 미달성\n",
      "어시스턴트), IBM 왓슨\n",
      "3단계: 전문가(숙련된 인간의 90% 이상) 문법 교정기(그래머리), 생성 이미지 모델(달리2) 미달성\n",
      "\n",
      "처리를 지원\n",
      "∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\n"
     ]
    }
   ],
   "source": [
    "result = retriever_tool.invoke(\"삼성전자가 만든 생성형 AI 이름을 찾아줘\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "도구 목록을 정의 합니다. 이는 Agent 에게 제공될 도구 목록입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TavilySearch(name='web_search', description='Use this tool to search on the web', client=<tavily.tavily.TavilyClient object at 0x10578b9e0>, max_results=6),\n",
       " Tool(name='pdf_retriever', description='Search and return information about SPRI AI Brief PDF file. It contains useful information on recent AI trends. The document is published on Dec 2023.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x106acce00>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x145541cd0>, search_kwargs={'k': 6}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x106accf40>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x145541cd0>, search_kwargs={'k': 6}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도구 목록 정의\n",
    "tools = [web_search_tool, retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_react_agent`\n",
    "\n",
    "ReAct Agent 를 생성합니다. 이는 도구 목록을 제공하고, 사용자의 질문에 대한 답변을 생성합니다.\n",
    "\n",
    "- `model`: 사용할 모델\n",
    "- `tools`: 도구 목록\n",
    "- `prompt`: 시스템 프롬프트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "simple_react_agent = create_react_agent(\n",
    "    model, tools, prompt=\"You are a helpful assistant. Answer in Korean.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**그래프 시각화**\n",
    "\n",
    "`visualize_graph` 함수는 그래프를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(simple_react_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 실행\n",
    "\n",
    "- `config` 파라미터는 그래프 실행 시 필요한 설정 정보를 전달합니다.\n",
    "    - `resursion_limit`: 그래프 실행 시 재귀 최대 횟수를 설정합니다.\n",
    "    - `thread_id`: 그래프 실행 시 스레드 아이디를 설정합니다.\n",
    "- `inputs`: 그래프 실행 시 필요한 입력 정보를 전달합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 메시지 출력 스트리밍은 [LangGraph 스트리밍 모드의 모든 것](https://wikidocs.net/265770) 을 참고해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "\n",
      "SPRi AI Brief |\n",
      "2023-12월호\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "KEY Contents\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "\n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "10\n",
      "\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\n",
      "처리를 지원\n",
      "\n",
      "처리를 지원\n",
      "∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "삼성전자가 개발한 생성형 AI의 이름은 '삼성 가우스'입니다. 이 AI 모델은 언어, 코드, 이미지의 3개 모델로 구성되어 있으며, 온디바이스에서 작동이 가능합니다. '삼성 가우스'는 사용자의 정보가 외부로 유출되지 않는 장점이 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "# Config 설정\n",
    "## recursion_limit : 노드를 반복횟수 (결과 실패시 리밋 10회)\n",
    "## thread_id : 챗 room uid \n",
    "config = {\"configurable\": {\"resursion_limit\": 10, \"thread_id\": \"abc123\"}}\n",
    "\n",
    "# 입력 설정\n",
    "inputs = {\n",
    "    \"messages\": [(\"human\", \"AI Brief 문서에서 삼성전자가 만든 생성형 AI 이름을 찾아줘\")]\n",
    "}\n",
    "\n",
    "# 그래프 스트림\n",
    "stream_graph(simple_react_agent, inputs, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추적: https://smith.langchain.com/public/145d8012-9791-4320-a17d-b2ec048d0110/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고**: `config` 는 이전의 값을 재활용 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "[{\"title\": \"What Is Claude 3.7 Sonnet? - Built In\", \"url\": \"https://builtin.com/artificial-intelligence/claude-3-7-sonnet\", \"content\": \"Claude 3.7 Sonnet is an AI model developed by Anthropic. Claude 3.7 Sonnet is hitting the market at an especially competitive moment in the artificial intelligence industry, with companies like OpenAI, Google, xAI and DeepSeek all racing to develop AI models with advanced reasoning capabilities. Claude 3.7 Sonnet is Anthropic’s first publicly available reasoning model. In “standard mode,” the model essentially functions as an upgraded version of Anthropic’s Claude 3.5 Sonnet, which excels at performing complex tasks that require rapid response, like knowledge retrieval, sales automation and computer programming. Anthropic says Claude 3.7 Sonnet is its best coding model to date — capable of spotting and fixing bugs, developing features, explaining technical concepts and suggesting improvements across different programming languages.\", \"score\": 0.9332426, \"raw_content\": \"What Is Claude 3.7 Sonnet? | Built In\\n \\n\\nCan't find your company? Create a company profile.\\nView All Jobs\\nFor Employers\\nJoin\\nLog In\\n\\nJobs\\nCompanies\\nRemote\\nArticles\\nSalaries\\nBest Places To Work\\nMy items\\n\\nArtificial Intelligence\\nAnthropic’s Claude 3.7 Sonnet Combines Quick Responses and Advanced Reasoning\\nAnthropic is stepping into the ring with the likes of OpenAI, xAI, Google and DeepSeek, launching a new “hybrid” model in an effort to achieve the most advanced reasoning capabilities.\\n\\nWritten by Ellen Glover\\nPublished on Feb. 26, 2025\\n\\n\\nImage: Shutterstock\\nAnthropic has unveiled its latest AI model, Claude 3.7 Sonnet, calling it its “most intelligent” to date. Released in February 2025, the large language model has “hybrid reasoning” capabilities, meaning it can think about its response — pausing to consider its answer before generating it — as well as deliver quick, real-time outputs when needed. Outperforming several of the industry’s top models, Claude 3.7 Sonnet excels at coding, software engineering, instruction-following, multimodal understanding and agentic tasks.\\nWhat Is Claude 3.7 Sonnet?\\nClaude 3.7 Sonnet is an AI model developed by Anthropic. With so-called “hybrid reasoning” capabilities, the model can switch between rapid responses and deep, reflective thinking within a single system.\\nClaude 3.7 Sonnet is hitting the market at an especially competitive moment in the artificial intelligence industry, with companies like OpenAI, Google, xAI and DeepSeek all racing to develop AI models with advanced reasoning capabilities. What sets Anthropic’s new model apart is its ability to switch between rapid responses and deep, reflective thinking within a single system. Most competing models just focus on one or the other.\\n“Claude 3.7 Sonnet can produce near-instant responses or extended, step-by-step thinking that is made visible to the user,” Anthropic explained in a blog post, claiming it creates a “more seamless experience” for users. “Just as humans use a single brain for both quick responses and deep reflection, we believe reasoning should be an integrated capability of frontier models rather than a separate model entirely.”\\nClaude 3.7 Sonnet can be accessed through the Claude chatbot across all subscription tiers (including the free tier), but its “extended thinking” mode is limited to Pro, Team and Enterprise subscribers. The model is also available through the Anthropic API, Amazon Bedrock and Google Cloud’s Vertex AI platforms.\\nWhat Is Claude 3.7 Sonnet?\\nClaude 3.7 Sonnet is a foundation model designed to understand and generate human-like text. Capable of providing both quick, pattern-based outputs as well as more nuanced, thought-out answers, it performs especially well in tasks involving coding, instruction-following, multimodal understanding and agentic capabilities.\\nClaude 3.7 Sonnet was developed by Anthropic, an AI research and development startup founded in 2021 by former OpenAI executives. Known for its Claude chatbot and large suite of language models, the company’s stated goal is to responsibly advance the field of generative AI, with an emphasis on safety and ethics. To that end, Anthropic develops some of the most advanced AI products on the market — right alongside top competitors — but does not release them until they have sufficiently met its robust safety measures.\\nAnthropic says it conducted extensive testing, training and evaluation of Claude 3.7 Sonnet, working with “external experts” to ensure it meets all of its security, safety and reliability standards. The company also claims Claude 3.7 Sonnet can make more nuanced distinctions between harmful and benign prompts, so it will reject or defer questions less frequently than previous Claude models.\\nMore AI Model NewsWhat Is Nvidia Cosmos?\\nWhat Can Claude 3.7 Sonnet Do?\\nClaude 3.7 Sonnet can do much of what other comparable models can do: answer questions, brainstorm ideas, summarize content and generate new content — accepting both images and text as inputs. But it stands out from other Anthropic models in a few important ways.\\nReasoning\\nClaude 3.7 Sonnet is Anthropic’s first publicly available reasoning model. In general, these kinds of models are designed to break down problems into smaller, more manageable steps, verifying facts along the way before generating a final answer. While they don’t necessarily replicate human thinking or reasoning, their process is modeled after deduction, with the aim of providing more accurate and reliable responses.\\nFunctioning as both a typical large language model and reasoning model in one, Claude 3.7 Sonnet lets users pick whether they want a quick answer from the model or whether they want it to think longer before answering.\\n\\nIn “standard mode,” the model essentially functions as an upgraded version of Anthropic’s Claude 3.5 Sonnet, which excels at performing complex tasks that require rapid response, like knowledge retrieval, sales automation and computer programming.\\nWhen “extended thinking mode” is turned on, the model creates “thinking content blocks” where it visually displays its internal reasoning to the user, according to Anthropic. Those insights are then incorporated into its final response, improving the model’s performance in math, physics, instruction-following and coding, among other tasks.\\n\\nThrough Anthropic’s API, users can control Claude 3.7 Sonnet’s “thinking” budget, meaning they can set a limit on how long the model should reason before responding (with a maximum of 128,000 tokens). This essentially allows them to balance speed and cost with the quality of the answer. In both standard and extended thinking modes, Claude 3.7 Sonnet costs $3 per million input tokens and $15 per million output tokens, including those used for thinking.\\nCoding\\nAnthropic says Claude 3.7 Sonnet is its best coding model to date — capable of spotting and fixing bugs, developing features, explaining technical concepts and suggesting improvements across different programming languages. Its extended thinking mode is specifically optimized for powering AI agents that can handle more complex tasks and workflows, thus accelerating the building process across the entire software development lifecycle.\\nIn addition to Claude 3.7 Sonnet, Anthropic released a preview of its own agentic coding tool called Claude Code. Acting as an “active collaborator,” the company says the tool can search and read code, edit files, write and run tests and use command tools — all the while keeping users “in the loop.”\\nAnthropic claims Claude Code can complete tasks like test-driven development, debugging complex issues and large-scale refactoring — tasks that would typically take a human more than 45 minutes of manual work. In a video demonstration, the tool was able to analyze a project with a simple command like, “Explain this project structure.” Using plain English in the command line, developers were able to modify their code, with Claude Code describing its changes, testing for errors and even pushing updates to GitHub.\\nClaude 3.7 Sonnet Use Cases\\nLike all of Anthropic’s models, Claude 3.7 can be used in all sorts of ways. The company has highlighted a few in its documentation:\\n\\nSoftware engineering: Claude 3.7 Sonnet specifically achieves “state-of-the-art” performance on software engineering benchmarks, according to Anthropic, so it is good at solving complex software-related issues. This makes it a strong tool for tasks like code generation, debugging and automating development workflows.\\nTicket routing: The model’s advanced natural language processing capabilities can be used to automatically sort and route customer support tickets based on factors like urgency, customer intent, priority, customer profile and more.\\nCustomer support agent: The model’s advanced conversational abilities can be used to build automated customer support agents that can handle inquiries in real time, providing around-the-clock support and managing high request volumes with accurate responses and “positive” interactions.\\nContent moderation: Specifically trained to be as “honest, helpful and harmless” as possible, the model can be used to moderate digital applications, helping to maintain a safe, respectful and productive environment.\\nLegal summarization: With its advanced natural language processing capabilities, the model can efficiently summarize legal documents, extracting key information to expedite the legal research process. It can be used to review contracts, assist with litigation preparation and support regulatory work, saving users time while maintaining accuracy.\\n\\nMore AI ContentAI Basics: Artificial Intelligence 101\\nHow Does Claude 3.7 Sonnet Compare to Other Models?\\nAnthropic compared Claude 3.7 Sonnet to other models of similar sizes and capabilities, including OpenAI’s o1 and o3-mini, DeepSeek’s R1 and xAI’s Grok 3, as well as its own Claude 3.5 Sonnet. These comparisons evaluated capabilities like software engineering, agentic tool use, instruction following, general reasoning, multimodal capabilities and agentic coding.\\nIn short: Claude 3.7 Sonnet outperformed most of its competitors across the majority of these tests when it was in extended thinking mode. However, it scored lower than Grok 3 in graduate-level reasoning (GPQA Diamond); o1 in multilingual Q&A (MMMLU); both Grok 3 and o1 in visual reasoning (MMMU); o1, o3-mini and R1 in math problem-solving (MATH 500); and Grok 3, o1, o3-mini and R1 in high school math competition (AIME 2024). Claude 3.7 Sonnet also performed well in standard mode, but it did not beat out its competitors as consistently as when it was in extended thinking mode.\\nBeyond these more traditional benchmarks, Claude 3.7 Sonnet outperformed all of Anthropic’s previous models in its Pokémon gameplay tests when it was in extended thinking mode.\\nClaude 3.7 Sonnet Limitations\\nLike any other AI model, Claude 3.7 Sonnet is capable of producing inaccurate responses, and may reflect the biases present in its training data in its outputs. It also does not perform as well as other models in math-related tasks when it is in standard mode. However, it seems to experience a notable boost in this area when it is in extended thinking mode.\\nRelated Reading3 Things We Need to Fix Before AI Agents Go Mainstream\\nHow to Access Claude 3.7 Sonnet\\nClaude 3.7 Sonnet can be accessed in several locations, including:\\n\\nClaude chatbot: Claude 3.7 Sonnet’s standard mode is available on all subscription tiers (Free, Pro, Team and Enterprise). However, its extended thinking mode is exclusive only to Pro, Team and Enterprise subscribers.\\nAnthropic’s API: Users can integrate Claude 3.7 Sonnet into their own applications by accessing it through Anthropic’s API. You can learn how to use the API to build with Claude in this step-by-step guide.\\nThird-party platforms: Claude 3.7 Sonnet is available on the Amazon Bedrock and Google Cloud’s Vertex AI platforms, where users can integrate and deploy the model into their own applications without having to manage the underlying infrastructure themselves.\\n\\nFrequently Asked Questions\\nIs Claude 3.7 Sonnet available?\\nYes — Claude 3.7 Sonnet is available through the Claude chatbot across all subscription tiers (including Free), but its extended thinking mode is exclusive to Pro, Team and Enterprise subscribers. Claude 3.7 Sonnet is also available through the Anthropic API, Amazon Bedrock and Google Cloud’s Vertex AI platforms.\\nIs Claude 3.7 Sonnet free?\\nYes — a standard version of Claude 3.7 Sonnet can be accessed for free through the Claude chatbot. However, its extended thinking capabilities are only available in the Pro, Team and Enterprise subscription tiers, which vary in price. Otherwise, the model costs $3 per million input tokens and $15 per million output tokens on the Anthropic API, Amazon Bedrock and Google Cloud’s Vertex AI platforms.\\nIs Claude 3.7 Sonnet multimodal?\\nYes — Claude 3.7 Sonnet accepts both text and image inputs, so it has multimodal capabilities. But it is only able to generate text responses.\\nIs Claude 3.7 Sonnet safe?\\nWhile no AI model is completely risk-free, Anthropic says it conducted extensive testing, training and evaluation of Claude 3.7 Sonnet, working with “external experts” to ensure it meets its security, safety and reliability standards. The company also claims Claude 3.7 Sonnet can make more nuanced distinctions between harmful and benign prompts, so it defers questions less frequently than prior models. Specifically, the model reduces unnecessary refusals by 45 percent in standard mode and 31 percent in extended thinking mode compared to Claude 3.5 Sonnet.\\nWhat is Claude Code?\\nClaude Code is an agentic coding tool developed by Anthropic that can autonomously perform advanced tasks like searching and reading code, editing files, writing and running tests, using command tools and even pushing updates to GitHub.\\nWhat is a reasoning model?\\nIn general, reasoning models are designed to analyze complex problems, break them down into management steps and refine their responses before delivering a final answer. The goal is to provide more accurate and reliable responses than standard language models, which generate quick, pattern-based outputs. In the case of Claude 3.7 Sonnet specifically, the model can switch between rapid responses and deep, reflective thinking within a single system.\\nRecent Artificial Intelligence Articles\\n 6 Top Facial Recognition Companies LightGBM: A Guide 20 AI in Education Examples to Know\\nExplore Job Matches.\\nJob Title or Keyword Clear search\\nLocation\\nNo Results Found\\nJob Type\\nClear Apply\\nSee Jobs\\n\\nJobs\\nCompanies\\nArticles\\nMy Items\\nMore\\n\\n\\nJoin\\nLog In\\n\\nTech Jobs\\nCompanies\\nArticles\\nRemote\\nSalaries\\nBest Places To Work\\nTech Hubs\\n\\nPost Job\\n\\n\\nBuilt In is the online community for startups and tech companies. Find startup jobs, tech news and events.\\n\\nAbout\\nOur Story\\nCareers\\nOur Staff Writers\\nContent Descriptions\\n\\nGet Involved\\nRecruit With Built In\\nBecome an Expert Contributor\\n\\nResources\\nCustomer Support\\nShare Feedback\\nReport a Bug\\nBrowse Jobs\\nTech A-Z\\n\\nTech Hubs\\nOur Sites\\n\\nLearning Lab User Agreement Accessibility Statement Copyright Policy Privacy Policy Terms of Use Your Privacy Choices/Cookie Settings CA Notice of Collection\\n© Built In 2025\"}, {\"title\": \"Claude 3.7 Sonnet is Anthropic's AI Resurgence\", \"url\": \"https://www.unite.ai/claude-3-7-sonnet-is-anthropics-ai-resurgence/\", \"content\": \"Claude 3.7 Sonnet is Anthropic’s AI Resurgence Claude 3.7 Sonnet is Anthropic’s AI Resurgence Billed as the company’s “most intelligent model to date” and the first hybrid reasoning AI on the market, Claude 3.7 Sonnet introduces some major enhancements over its predecessor (Claude 3.5 Sonnet) in speed, reasoning, and real-world task performance. For many regular AI users, Claude 3.5 Sonnet had already been a go-to tool. Rather than releasing a separate Claude reasoning edition, Anthropic has merged both quick and deep thinking into one AI. Power users can even fine-tune how much the AI thinks: through the API, developers can set a token budget for reasoning, telling Claude how long to ponder (from just a few steps up to a massive 128k-token thought process) before finalizing an answer.\", \"score\": 0.92442214, \"raw_content\": \"Published Time: 2025-02-25T17:24:00+00:00\\nClaude 3.7 Sonnet is Anthropic’s AI Resurgence - Unite.AI\\n\\n\\nAI Tools\\nBusiness\\nChatbots\\nCode Generators\\nEducation\\nCrypto Trading\\nHeadshot Generators\\nImage Enhancers\\nImage Generators\\nMarketing Tools\\nMusic Generators\\nSEO\\nStock Trading\\nText to Speech\\nTranscription\\nTranslation\\nVideo Enhancers\\nVideo Generators\\nVoice Generators\\nWriting Tools\\n\\n\\nEvents\\nAI Conferences\\nAR, VR & XR Conferences\\nCybersecurity Conferences\\nRobotics Conferences\\nSEO Conferences\\n\\n\\nNews\\nArtificial Intelligence\\nArtificial General Intelligence\\nBrain Machine Interface\\nCybersecurity\\nEthics\\nHealthcare\\nInterviews\\nFunding\\nQuantum Computing\\nRegulation\\nRobotics\\nSurveillance\\nThought Leaders\\n\\n\\nCertifications\\nBlockchain\\nCloud\\nCybersecurity\\nData Science\\nMachine Learning\\nNatural Language Processing\\nPrompt Engineering\\nPython\\nRobotic Process Automation\\nTensorFlow\\n\\n\\nPython Libraries\\nData Science\\nDeep Learning\\nImage Processing\\nMachine Learning\\nNatural Language Processing\\n\\n\\nDomain Names\\nNewsletters\\nContact Us\\n\\nConnect with us\\n\\n\\n\\n\\n\\n\\n\\nUnite.AI\\nClaude 3.7 Sonnet is Anthropic’s AI Resurgence\\n\\n\\nAI Tools\\n\\n\\n\\n\\n\\nGenerative AI\\n            *   Business Plans\\n            *   Cartoonize\\n            *   Code\\n            *   Emails\\n            *   Headshots\\n            *   Images\\n            *   Media Kits\\n            *   Music\\n            *   Pitch Deck\\n            *   Presentations\\n            *   Sketch\\n            *   Video\\n            *   Voice\\n            *   Writing\\n\\n\\n\\n\\nBusiness AI\\n        *   Business\\n        *   Chatbots\\n        *   Doc Management\\n        *   ETL\\n        *   Legal Assistants\\n        *   Marketing\\n        *   Public Speaking\\n        *   Recruiting\\n        *   Resume & CV\\n        *   SEO\\n        *   Social Media\\n        *   Text to Speech\\n        *   White Label\\n        *   Work Management\\n\\n\\n\\n\\nOptimization AI\\n        *   AI Assistants\\n        *   App Builders\\n        *   Audio Enhancers\\n        *   Chrome Extensions\\n        *   Data Cleaning\\n        *   Image Enhancers\\n        *   Image Extenders\\n        *   Image Resizer\\n        *   Photo Editing\\n        *   Transcription\\n        *   Translation\\n        *   Video Enhancers\\n        *   Website Builders\\n\\n\\n\\n\\nToolkit AI\\n        *   CRM Platforms\\n        *   Data Analysts\\n        *   Education\\n        *   Fashion Designers\\n        *   Medical Scribes\\n        *   Trading Crypto\\n        *   Trading Stocks\\n        *   Task Management\\n        *   Trend Analysis\\n\\n\\n\\n\\n\\n\\n\\nCertifications\\n\\nBlockchain Certifications\\nChatbots\\nCloud\\nCybersecurity\\nData Science\\nMachine Learning\\nNatural Language Processing\\nPrompt Engineering\\nPython\\nRobotic Process Automation\\nTensorFlow\\n\\n\\nEvents\\nAI Conferences\\nAR, VR & XR Conferences\\nCybersecurity Conferences\\nRobotics Conferences\\nSEO Conferences\\n\\n\\nNews\\nAll\\nArtificial Intelligence\\nArtificial General Intelligence\\nAugmented Reality\\nBrain Machine Interface\\nCybersecurity\\nEthics\\nFuturist Series\\nHealthcare\\nFunding\\nQuantum Computing\\nRegulation\\nRobotics\\nSurveillance\\n\\n\\nInterviews\\nThought Leaders\\n.AI Domains\\n\\nArtificial Intelligence\\nClaude 3.7 Sonnet is Anthropic’s AI Resurgence\\n\\nPublished\\n1 hour agoon\\nFebruary 25, 2025 \\nBy\\nAlex McFarland\\nTable Of Contents\\n\\n(Alex McFarland/Unite AI)\\nAnthropic has released Claude 3.7 Sonnet, a highly-anticipated upgrade to its large language model (LLM) family. Billed as the company’s “most intelligent model to date” and the first hybrid reasoning AI on the market, Claude 3.7 Sonnet introduces some major enhancements over its predecessor (Claude 3.5 Sonnet) in speed, reasoning, and real-world task performance.\\nThe rollout comes amid fast advances from competitors like OpenAI and xAI’s recent Grok 3, leading many AI enthusiasts (including me) to view this launch as Anthropic’s answer to recent innovations. The new model aims to blend quick conversational answers with deeper analytical thinking in one system – a unified approach that could show us what future interaction with AI will look like.\\nLong-Awaited Upgrade to a Beloved AI Assistant\\nFor many regular AI users, Claude 3.5 Sonnet had already been a go-to tool. It was regarded as one of the best out there. However, in recent months Anthropic faced growing pressure. The AI industry has been going crazy with new features and models – OpenAI’s ChatGPT gained voice, multi-step reasoning abilities, and deep research. Grok 3 made its debut with real-time X data, and other platforms like Perplexity and Gemini kept the releases coming. Many observers started to note that Anthropic was starting to fall behind. The community had been eagerly awaiting Anthropic’s response, with expectations that a new Claude model was due any day.\\nClaude 3.7 Sonnet arrived at last to meet those expectations. It is a significant leap forward from Claude 3.5, rather than a minor tweak. Anthropic touts it as a comprehensive upgrade: faster, smarter, and more versatile.\\nThe model’s speed and output quality are striking. In my own tests, I found it to be incredibly fast compared to the last version, processing lengthy text inputs almost instantaneously. Given Anthropic’s slow update cycle, the 3.7 release feels like a long-awaited catch-up that reclaims Claude’s position in the AI race. Claude 3.7 doubles down on what made users love Claude 3.5 – exceptional performance in practical tasks – while adding innovative reasoning capabilities under the hood.\\nHybrid Reasoning: Quick Answers and Deep Thinking in One\\nThe headline feature of Claude 3.7 Sonnet is its hybrid reasoning capability. In simple terms, this model can operate in two modes: a standard mode for near-instant responses, and a new “extended thinking” mode where it works through problems step-by-step, showing its chain-of-thought to the user.\\nRather than releasing a separate Claude reasoning edition, Anthropic has merged both quick and deep thinking into one AI. “Just as humans use a single brain for both quick responses and deep reflection, we believe reasoning should be an integrated capability… rather than a separate model entirely,” the company explained in its announcement, emphasizing a unified approach for a seamless user experience.\\nIn practice, this means users can decide when they want a fast answer and when to let Claude deliberate at length. A simple toggle lets you switch to extended mode if a question requires detailed analysis or multi-step logic. In standard mode, Claude 3.7 Sonnet functions like an improved version of 3.5 – faster and more refined, but with the familiar quick conversational style. In extended mode, the AI “self-reflects” before answering, writing out its reasoning process internally (and making it visible) to arrive at more accurate or complex solutions.\\nThe chain-of-thought scrolls out step by step on screen, a feature that has become popular in other advanced AI systems and now finally comes to Claude.\\nAlex McFarland/Unite AI\\nAnthropic’s philosophy here deliberately contrasts with some competitors. OpenAI, for instance, has offered separate models or modes, which some find confusing to juggle. Claude 3.7’s all-in-one approach is meant to simplify things for users. Switching between modes is straightforward, and prompt style remains the same. Power users can even fine-tune how much the AI thinks: through the API, developers can set a token budget for reasoning, telling Claude how long to ponder (from just a few steps up to a massive 128k-token thought process) before finalizing an answer. This granular control lets one trade off speed for thoroughness on demand.\\nKey Improvements in Claude 3.7 Sonnet:\\nHere are some of the main improvements that we see from Claude 3.7 Sonnet:\\n\\nHybrid Reasoning Modes – Offers both instant answers and an Extended Thinking mode where the AI works through problems stepwise with visible reasoning. Users choose the mode per query, unifying fast chat and deep analysis in one system.\\nUnified Model Philosophy – Integrates quick and reflective thinking in a single AI “brain” for ease of use. This contrasts with rivals requiring multiple models or plugins, reducing complexity for the end-user.\\nSpeed and Responsiveness – Delivers answers faster than Claude 3.5. Early tests show noticeably snappier performance in standard mode.\\nExpanded Thinking Control – Through the API, users can limit or extend the AI’s reasoning length (up to 128,000 tokens) to balance speed vs. quality as needed. This ensures extended mode is used only as much as necessary.\\nReal-World Task Focus – According to the company, Claude 3.7’s training was shifted toward practical business and creative tasks rather than tricky math Olympiad puzzles. The model excels at everyday problem-solving and tasks that reflect common use cases.\\nCoding and Tool Use – Stronger performance in programming tasks, especially front-end web development. Anthropic even launched a companion tool, Claude Code, which allows developers to use Claude from the command line for writing and fixing code. Early benchmarks show Claude 3.7 topping charts in solving real software issues.\\n\\nLimitations and What’s Next for AI Users\\nDespite all the excitement, Claude 3.7 Sonnet is not without limits, and it is not a magic bullet for all AI challenges. For one, Anthropic consciously de-emphasized certain domains in training this model. They “optimized somewhat less for math and computer science competition problems” in favor of more everyday business tasks. This means that while Claude 3.7 can certainly solve math and coding questions (often better than 3.5 could), it might not top the leaderboard on every academic benchmark or puzzle. Users whose needs skew toward complex math proofs or specialized coding contests might still find areas where Claude’s answers require double-checking or where a competitor’s model tuned for that niche does better. Anthropic seems to have accepted this trade-off, aiming the model at practical utility over theoretical prowess.\\nAdditionally, Extended Thinking mode, while powerful, introduces some complexity. It is inherently slower than the standard mode; when the AI is in deep thought, users will notice a brief pause as it works through its reasoning. This is expected – trading speed for thoroughness – but it means users must decide when they actually need that extra power. In many everyday chat queries, the standard mode will suffice and be more efficient. There is also the fact that extended reasoning can sometimes overdo it and provide a lot more than you actually need. In some cases, this could overwhelm or veer off track. Anthropic will need to ensure that the AI’s willingness to “go big” with ideas remains relevant and on-topic. Users may learn to prompt more precisely or set token limits to curb runaway tangents.\\nIn terms of knowledge and modalities, Claude 3.7 remains primarily a text-based model. Unlike ChatGPT’s vision features or other models incorporating image or voice inputs, Claude does not yet natively “see” images or speak aloud. Its strength is in textual understanding and generation. For most, this is not necessarily a downside – but those hoping for a Claude that can analyze a photo or handle voice commands will have to wait for future iterations. Anthropic has not announced any multimodal functionality in Sonnet at this time. The focus has clearly been on refining the core language abilities and reasoning process.\\nThe Bottom Line\\nClaude 3.7 Sonnet’s release is a statement that Anthropic is very much in the game alongside OpenAI, Google/DeepMind, and new players like xAI. For AI enthusiasts and developers, it adds another top-tier model to experiment with, one that offers a unique twist with its hybrid reasoning.\\nIn the competitive AI industry, Anthropic’s latest move may also influence how companies position their models. By choosing not to do a massive model size jump or a glitzy multi-modal demo, but instead refining the user experience (unification of modes, speed, practical use cases), Anthropic is carving a niche focused on usability and reliability.\\nOverall, Claude 3.7 Sonnet is a pivotal moment for Anthropic. It is an evolution of the Claude series that shows the company learning from the community’s needs – doubling down on strengths while addressing weaknesses. There are still areas to watch (and future Claude iterations to anticipate), but this release has clearly re-energized Anthropic’s user base.\\nRelated Topics:anthropicclaude\\nDon't MissImandraX: A Breakthrough in Neurosymbolic AI Reasoning and Automated Logical Verification\\n\\nAlex McFarland\\n\\nAlex McFarland is an AI journalist and writer exploring the latest developments in artificial intelligence. He has collaborated with numerous AI startups and publications worldwide.\\n\\nYou may like\\n*   Citations: Can Anthropic’s New Feature Solve AI’s Trust Problem? *   Breaking Data Barriers: Can Anthropic’s Model Context Protocol Enhance AI Performance? *   Anthropic Just Became America’s Most Intriguing AI Company *   Claude’s Model Context Protocol (MCP): A Developer’s Guide *   Claude Feature Enables Customized Writing Styles *   Amazon Seeks to Deepen AI Partnership with Anthropic Through Strategic Chip-Focused Investment\\n\\nAbout Us\\nMeet the Team\\nOur Charter\\n.AI Domain Names\\nPress Tools\\nContact Us\\n\\nAdvertiser Disclosure: Unite.AI is committed to rigorous editorial standards to provide our readers with accurate information and news. We may receive compensation when you click on links to products we reviewed.\\n\\n\\n\\n\\n\\n\\n\\nCopyright © 2025 Unite.AI\\n\\nEditorial Policy\\nPrivacy Policy\\nTerms and Conditions\\n\\n\"}, {\"title\": \"Claude 3.7 Sonnet debuts with \\\"extended thinking\\\" to tackle complex ...\", \"url\": \"https://arstechnica.com/ai/2025/02/claude-3-7-sonnet-debuts-with-extended-thinking-to-tackle-complex-problems/\", \"content\": \"Claude 3.7 Sonnet debuts with “extended thinking” to tackle complex problems - Ars Technica On Monday, Anthropic announced Claude 3.7 Sonnet, a new AI language model with a simulated reasoning (SR) capability called \\\"extended thinking,\\\" allowing the system to work through problems step by step. 3.7's predecessor, Claude 3.5 Sonnet, was excellent at programming tasks compared to other AI models in our experience, and according to Anthropic, early testing indicates strong performance in that area. An example of Claude 3.7 Sonnet with extended thinking is asked, \\\"Compose 5 original dad jokes that are not found anywhere in the world.\\\" Credit: Benj Edwards\", \"score\": 0.8858788, \"raw_content\": \"Published Time: 2025-02-24T22:23:34+00:00\\nClaude 3.7 Sonnet debuts with “extended thinking” to tackle complex problems - Ars Technica\\nSkip to content\\nArs Technica home\\nSections\\nForum\\nSubscribe\\n\\n\\nAI\\nBiz & IT\\nCars\\nCulture\\nGaming\\nHealth\\nPolicy\\nScience\\nSecurity\\nSpace\\n\\nTech\\n\\n\\nFeature\\n\\nReviews\\n\\nStore\\n\\n\\nAI\\n\\nBiz & IT\\nCars\\nCulture\\nGaming\\nHealth\\nPolicy\\nScience\\nSecurity\\nSpace\\nTech\\n\\nForum\\nSubscribe\\nStory text\\nSize  Width *  Links \\n* Subscribers only\\nLearn more\\nPin to story\\nTheme\\n\\nHyperLight\\nDay & Night\\nDark\\nSystem\\n\\nSearch dialog...\\nSign In\\nSign in dialog...\\nSign in\\nponder me this\\nClaude 3.7 Sonnet debuts with “extended thinking” to tackle complex problems\\nAnthropic's first simulated reasoning model is a beast at coding tasks.\\nBenj Edwards – Feb 24, 2025 10:23 PM | 22\\n \\nCredit: Anthropic\\nCredit: Anthropic\\nText settings\\nStory text\\nSize  Width *  Links \\n* Subscribers only\\nLearn more\\nMinimize to nav\\nOn Monday, Anthropic announced Claude 3.7 Sonnet, a new AI language model with a simulated reasoning (SR) capability called \\\"extended thinking,\\\" allowing the system to work through problems step by step. The company also revealed Claude Code, a command line AI agent for developers currently available as a limited research preview.\\nAnthropic calls Claude 3.7 the first \\\"hybrid reasoning model\\\" on the market, giving users the option to choose between quick responses or extended, visible chain-of-thought processing similar to OpenAI's o1 and o3 series models, Google's Gemini 2.0 Flash Thinking, and DeepSeek's R1. When using Claude 3.7's API, developers can specify exactly how many tokens the model should use for thinking, up to its 128,000 token output limit.\\nThe new model is available across all Claude subscription plans, and the extended thinking mode feature is available on all plans except the free tier. API pricing remains unchanged at $3 per million input tokens and $15 per million output tokens, with thinking tokens included in the output pricing since they are part of the context considered by the model.\\nIn another interesting development—since Claude 3.5 Sonnet was known as something of a Goody Two-shoes in the AI world—Anthropic said that it had reduced unnecessary refusals in 3.7 Sonnet by 45 percent. In other words, 3.7 Sonnet is more likely to do what you ask without complaining about ethical boundaries, which can otherwise pop up in innocent situations when interpreted incorrectly by the neural network running under Claude's hood.\\nArs Video\\nIn benchmarks, Anthropic's latest model seems to hold its own, and even excels in at least one category in particular: coding. 3.7's predecessor, Claude 3.5 Sonnet, was excellent at programming tasks compared to other AI models in our experience, and according to Anthropic, early testing indicates strong performance in that area. The company claims Claude 3.7 Sonnet achieved top scores on SWE-bench Verified, which evaluates how AI models handle real-world software issues, and also in TAU-bench, which tests AI agents on complex tasks with user and tool interactions.\\n\\nA chart showing self-reported Claude 3.7 Sonnet benchmark results. Credit: Anthropic\\nAiming at software developers, Anthropic has also expanded its GitHub integration to all Claude plans, allowing devs to connect code repositories directly to Claude for bug fixes, feature development, and documentation work.\\nIn our personal experience creating hobby programs with Claude 3.5 Sonnet over the past six months, the tool proved valuable for quickly prototyping projects, but we often ran up against usage limits. So far, Anthropic has not announced a subscription plan beyond the existing \\\"Claude Pro\\\" ($20/month) that might extend them, though we suspect developers who come to rely on 3.7 are soon going to need a plan more along the lines of OpenAI's ChatGPT Pro that features vastly expanded usage options for $200 a month. As an aside, our subjective experience with o1 and o3 in coding aligns with the benchmarks in the chart above; they have not been as good as Sonnet at coding.\\nAnd speaking of upgrades, we might as well talk about the name. Claude 3.5 Sonnet launched in June 2024, but it received an update in October with a nearly identical name (sometimes referred to as \\\"Claude 3.5 Sonnet (new) or \\\"Claude 3.5 Sonnet (October 2024)\\\") that some users criticized as confusing. As a result, some users began unofficially calling that version \\\"Claude 3.6 Sonnet\\\" instead. Apparently, Anthropic got the message on the desire for clearer naming practices, writing \\\"Lesson learned on naming\\\" in a footnote on the Claude 3.7 release page.\\nTaking “extended reasoning” for a spin\\nLike other SR models, Claude 3.7, with extended thinking, tries to work through more complex problems by throwing more tokens at them through an ingrained simulated reasoning process. Just like o1, o3, and DeepSeek R1, you can see the \\\"thinking\\\" process going through Claude 3.7's simulated mind while it works out an ideal answer.\\nTo test it out briefly, we gave it a couple of simple tasks, including our time-honored (and now likely compromised as part of training datasets scraped from the web) test of asking it about the origin of the \\\"magenta\\\" color name.\\n\\nAn example of Claude 3.7 Sonnet with extended thinking is asked, \\\"Would the color be called 'magenta' if the town of Magenta didn't exist?\\\" Credit: Benj Edwards\\nInterestingly, xAI's Grok 3 with \\\"thinking\\\" (its SR mode) enabled was the first model that definitively gave us a \\\"no\\\" and not an \\\"it's not likely\\\" to the magenta question. Claude 3.7 Sonnet with extended thinking also impressed us with our second-ever firm \\\"no,\\\" then an explanation.\\nIn another informal test, we asked 3.7 Sonnet with extended thinking to compose five original dad jokes. We've found in the past that our old prompt, \\\"write 5 original dad jokes,\\\" was not specific enough and always resulted in canned dad jokes pulled directly from training data, so we asked, \\\"Compose 5 original dad jokes that are not found anywhere in the world.\\\"\\n\\nAn example of Claude 3.7 Sonnet with extended thinking is asked, \\\"Compose 5 original dad jokes that are not found anywhere in the world.\\\" Credit: Benj Edwards\\nClaude made some attempts at crafting original jokes, although we'll let you judge whether they are funny or not. We will likely put 3.7 Sonnet's SR capabilities to the test more exhaustively in a future article.\\nAnthropic’s first agent: Claude Code\\nSo far, 2025 has been the year of both SR models (like R1 and o3) and agentic AI tools (like OpenAI's Operator and Deep Research). Not to be left out, Anthropic has announced its first agentic tool, Claude Code.\\nClaude Code operates directly from a console terminal and is an autonomous coding assistant. It allows Claude to search through codebases, read and edit files, write and run tests, commit and push code to GitHub repositories, and execute command line tools while keeping developers informed throughout the process.\\nIntroducing Claude Code.\\nAnthropic also aims for Claude Code to be used as an assistant for debugging and refactoring tasks. The company claims that during internal testing, Claude Code completed tasks in a single session that would typically require 45-plus minutes of manual work.\\nClaude Code is currently available only as a \\\"limited research preview,\\\" with Anthropic stating it plans to improve the tool based on user feedback over time. Meanwhile, Claude 3.7 Sonnet is now available through the Claude website, the Claude app, Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI.\\n\\nBenj Edwards Senior AI Reporter\\nBenj Edwards Senior AI Reporter\\nBenj Edwards is Ars Technica's Senior AI Reporter and founder of the site's dedicated AI beat in 2022. He's also a tech historian with almost two decades of experience. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.\\n22 Comments\\nComments\\nForum view\\n Loading comments...\\nPrev story\\nNext story\\nMost Read\\n\\n\\n\\n\\nAsteroid 2024 YR4 is going to miss Earth, but the story doesn’t end there\\n\\n\\n\\n\\nISPs fear wave of state laws after New York’s $15 broadband mandate\\n\\n\\n\\n\\nJudges block DOGE access to personal data in loss for Trump administration\\n\\n\\n\\n\\nRobot with 1,000 muscles twitches like human while dangling from ceiling\\n\\n\\n\\n\\nIn war against DEI in science, researchers see collateral damage\\n\\n\\n\\nCustomize\\nby Taboolaby Taboola\\nSponsored LinksSponsored Links\\nPromoted LinksPromoted Links\\nLearn More: Rheumatoid ArthritisGoodRx Learn More\\nUndo\\nFor Mountain View Residents Only: Claim Your Massive Welcome Bonus!McLuck | Play Now Install Now\\nUndo\\n3 Dividend Stocks to Buy NowZacks Investment Research Learn More\\nUndo\\nCalifornia : Gov’t Gives Homeowners A Massive Tax Break To Go SolarEnergy Bill Program Learn More\\nUndo\\nThis Mascara is Made With Older Women in MindPrime Prometics Learn More\\nUndo\\nInvest in Property With Historic Average 17% Yearly ReturnInvest With Roots Learn More\\nUndo\\nArs Technica has been separating the signal from the noise for over 25 years. With our unique combination of technical savvy and wide-ranging interest in the technological arts and sciences, Ars is the trusted source in a sea of information. After all, you don’t need to know everything, only what’s important.\\n\\nMore from Ars\\n\\nAbout Us\\nStaff Directory\\nNewsletters\\nArs Videos\\nGeneral FAQ\\nRSS Feeds\\n\\nContact\\n\\nContact us\\nAdvertise with us\\nReprints\\n\\nPrivacy Configurations\\n© 2025 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Ars Technica Addendum and Your California Privacy Rights. Ars Technica may earn compensation on sales from links on this site. Read our affiliate link policy. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices\\nSearch dialog...\\nSign in dialog...\\nSign in\\n\"}, {\"title\": \"Anthropic's Claude 3.7 Sonnet is here and results are insane\", \"url\": \"https://www.bleepingcomputer.com/news/artificial-intelligence/anthropics-claude-37-sonnet-is-here-and-results-are-insane/\", \"content\": \"Remove Security Tool and SecurityTool (Uninstall Guide) Anthropic has started rolling out Claude 3.7 Sonnet, the company's most advanced model and the first hybrid reasoning model it has shipped. Early tests show that Claude 3.7 Sonnet is outperforming rivals, including OpenAI's ChatGPT models and China's DeepSeek. SWE-bench Verified shows Claude 3.7 Sonnet is the best model for coding According to a benchmark test called “Software engineering (SWE-bench verified),” Claude 3.7 Sonnet is at the top with roughly 62% accuracy, which goes up to 70% when using extra test-time “scaffolding.” Competing models, including Claude 3.5 Sonnet and OpenAI’s variants, sit closer to the 50% range. At BleepingComputer, he covers technology news with a strong focus on Microsoft and Windows-related stories.\", \"score\": 0.8684817, \"raw_content\": \"Published Time: 2025-02-25T08:07:57-05:00\\nAnthropic's Claude 3.7 Sonnet is here and results are insane\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNews\\n\\nFeatured\\n\\nLatest\\n\\n\\nNorth Korean hackers linked to $1.5 billion ByBit crypto heist\\n\\nAustralia bans all Kaspersky products on government systems\\nBeware: PayPal \\\"New Address\\\" feature abused to send phishing emails\\n\\nMicrosoft tests ad-supported Office apps for Windows users\\n\\n\\nAnthropic's Claude 3.7 Sonnet is here and results are insane\\n\\nSave an extra $40 on a lifetime of Koofr 1TB cloud storage in this deal\\nOrange Group confirms breach after hacker leaks company documents\\nOpenAI bans ChatGPT accounts used by North Korean hackers\\n\\n\\n\\nTutorials\\n\\nLatest\\n\\nPopular\\n\\n\\nHow to access the Dark Web using the Tor Browser\\n\\nHow to enable Kernel-mode Hardware-enforced Stack Protection in Windows 11\\nHow to use the Windows Registry Editor\\n\\nHow to backup and restore the Windows Registry\\n\\n\\nHow to start Windows in Safe Mode\\n\\nHow to remove a Trojan, Virus, Worm, or other Malware\\nHow to show hidden files in Windows 7\\nHow to see hidden files in Windows\\n\\n\\n\\nVirus Removal Guides\\n\\nLatest\\nMost Viewed\\n\\nRansomware\\n\\n\\nRemove the Theonlinesearch.com Search Redirect\\n\\nRemove the Smartwebfinder.com Search Redirect\\nHow to remove the PBlock+ adware browser extension\\n\\nRemove the Toksearches.xyz Search Redirect\\n\\n\\nRemove Security Tool and SecurityTool (Uninstall Guide)\\n\\nHow to Remove WinFixer / Virtumonde / Msevents / Trojan.vundo\\nHow to remove Antivirus 2009 (Uninstall Instructions)\\n\\nHow to remove Google Redirects or the TDSS, TDL3, or Alureon rootkit using TDSSKiller\\n\\n\\nLocky Ransomware Information, Help Guide, and FAQ\\n\\nCryptoLocker Ransomware Information Guide and FAQ\\nCryptorBit and HowDecrypt Information Guide and FAQ\\nCryptoDefense and How_Decrypt Ransomware Information Guide and FAQ\\n\\n\\n\\nDownloads\\n\\nLatest\\n\\nMost Downloaded\\n\\n\\nQualys BrowserCheck\\n\\nSTOPDecrypter\\nAuroraDecrypter\\n\\nFilesLockerDecrypter\\n\\n\\nAdwCleaner\\n\\nComboFix\\nRKill\\nJunkware Removal Tool\\n\\n\\n\\nDeals\\n\\n\\nCategories\\n\\n\\neLearning\\n\\nIT Certification Courses\\nGear + Gadgets\\nSecurity\\n\\n\\n\\nVPNs\\n\\n\\nPopular\\n\\n\\nBest VPNs\\n\\nHow to change IP address\\nAccess the dark web safely\\nBest VPN for YouTube\\n\\n\\n\\nForums\\n\\n\\nMore\\n\\nStartup Database\\nUninstall Database\\nGlossary\\nChat on Discord\\nSend us a Tip!\\nWelcome Guide\\n\\n\\n\\nHome\\n\\nNews\\nArtificial Intelligence\\n\\nAnthropic's Claude 3.7 Sonnet is here and results are insane\\n\\n\\n\\n\\n\\nAnthropic's Claude 3.7 Sonnet is here and results are insane\\nBy\\nMayank Parmar\\n\\nFebruary 25, 2025\\n08:07 AM\\n0\\n\\n\\nAnthropic has started rolling out Claude 3.7 Sonnet, the company's most advanced model and the first hybrid reasoning model it has shipped.\\nEarly tests show that Claude 3.7 Sonnet is outperforming rivals, including OpenAI's ChatGPT models and China's DeepSeek.\\nIn a blog post, Anthropic noted that its newest model combines fast, straightforward answers with the ability to “think” step-by-step for complex tasks. This makes the Claude 3.7 model the best for programming, and these claims are backed by benchmarks.\\n\\nSWE-bench Verified shows Claude 3.7 Sonnet is the best model for coding\\nAccording to a benchmark test called “Software engineering (SWE-bench verified),” Claude 3.7 Sonnet is at the top with roughly 62% accuracy, which goes up to 70% when using extra test-time “scaffolding.”\\nCompeting models, including Claude 3.5 Sonnet and OpenAI’s variants, sit closer to the 50% range.\\n\\\"Software engineering (SWE-bench verified)\\\" is a benchmarking standard to see how well an AI model does when asked to code a program.\\nThese results show that Claude 3.7 Sonnet is significantly ahead of its competitors in terms of coding.\\nAGI moment for some users\\nUsers are also claiming that the results are insane.\\nFor example, in a thread, Reddit users noted that the model delivered outstanding results when they used it to create apps or even games.\\n“Claude Code was my ‘Feel the AGI moment.’ I’ve thrown bugs at this thing that no other models could fix, but Claude Code blasted through them,\\\" one user wrote in a Reddit thread.\\nAnother user added: “3.7 just slapped out an entire project I had been working on for months—5000 lines of code, front-end, debugging example, all from scratch. It didn’t stop until the job was done.”\\n\\nClaude 3.7 Sonnet benchmarks\\nAdditionally, Claude 3.7 Sonnet appears to excel in most categories, with its “extended thinking” mode boosting accuracy on tasks like math and science.\\nOther models, such as OpenAI’s 0.1 and DeepSeek R1, trail behind on many of these tests.\\nRelated Articles:\\nOpenAI bans ChatGPT accounts used by North Korean hackers\\nGoogle Chrome's AI-powered security feature rolls out to everyone\\nMicrosoft raises rewards for Copilot AI bug bounty program\\nChinese cyberspies use new SSH backdoor in network device hacks\\nGoogle says hackers abuse Gemini AI to empower their attacks\\n\\nAI\\nAnthropic\\nClaude\\nClaude 3.7\\n\\nOpenAI\\n\\n\\n\\n\\n\\n\\n\\n\\nMayank Parmar\\nMayank Parmar is an technology entrepreneur who is currently pursuing an MBA. At BleepingComputer, he covers technology news with a strong focus on Microsoft and Windows-related stories. He is always poking under the hood of Windows, looking for the latest secrets to reveal.\\n\\nPrevious Article\\n\\nPost a Comment Community Rules\\nYou need to login in order to post a comment\\nNot a member yet? Register Now\\nYou may also like:\\nPopular Stories\\n\\n Beware: PayPal \\\"New Address\\\" feature abused to send phishing emails\\n Russia warns financial sector of major IT service provider hack\\n Fake CS2 tournament streams used to steal crypto, Steam accounts\\n\\nSponsor Posts\\n\\n Discover full attack chains and identify their root cause. Learn more about Automated Security Validation.\\n Get the GOAT Guide to learn how to start validating, start defending, and start winning.\\n RDP Security Simplified - No VPN, No Firewall Exposure. Get a free TruGrid business trial.\\n Integrating LLMs into security operations using Wazuh. Learn how to get started.\\n 5 Browser Security Threats Overlooked by Security Tools. Get the Free Report\\n\\nFollow us:\\n\\n\\n\\n\\n\\n\\n\\nMain Sections\\n\\nNews\\nVPN Buyer Guides\\nSysAdmin Software Guides\\nDownloads\\nVirus Removal Guides\\nTutorials\\nStartup Database\\nUninstall Database\\nGlossary\\n\\nCommunity\\n\\nForums\\nForum Rules\\nChat\\n\\nUseful Resources\\n\\nWelcome Guide\\nSitemap\\n\\nCompany\\n\\nAbout BleepingComputer\\nContact Us\\nSend us a Tip!\\nAdvertising\\nWrite for BleepingComputer\\nSocial & Feeds\\nChangelog\\n\\nTerms of Use - Privacy Policy - Ethics Statement - Affiliate Disclosure\\nCopyright @ 2003 - 2025 Bleeping Computer® LLC - All Rights Reserved\\n\\n\\nLogin\\nUsername \\nPassword \\nRemember Me\\nSign in anonymously\\n Sign in with Twitter\\n\\nNot a member yet? Register Now\\n\\nReporter\\nHelp us understand the problem. What is going on with this comment?\\n\\nSpam\\nAbusive or Harmful\\nInappropriate content\\nStrong language\\nOther\\n\\nRead our posting guidelinese to learn what content is prohibited.\\nSubmitting...\\nSUBMIT\\n\"}, {\"title\": \"Anthropic's Claude 3.7 Sonnet is now available in Amazon Bedrock\", \"url\": \"https://aws.amazon.com/about-aws/whats-new/2025/02/anthropics-claude-3-7-sonnet-amazon-bedrock/\", \"content\": \"Anthropic's Claude 3.7 Sonnet is now available in Amazon Bedrock - AWS About AWS Contact Us Support   English   My Account   AWS Management Console AWS Support Overview AWS re:Post AWS re:Post Anthropic's Claude 3.7 Sonnet is now available in Amazon Bedrock Anthropic's Claude 3.7 Sonnet hybrid reasoning model, their most intelligent model to date, is now available in Amazon Bedrock. Claude 3.7 Sonnet is now available in Amazon Bedrock in the US East (N. For more information and to learn more read the AWS News Blog and Claude in Bedrock product detail page. Learn About AWS What Is AWS? AWS Accessibility AWS Cloud Security AWS Partners Developers on AWS AWS re:Post AWS Support Overview AWS support for Internet Explorer ends on 07/31/2022.\", \"score\": 0.7646988, \"raw_content\": \"Anthropic's Claude 3.7 Sonnet is now available in Amazon Bedrock - AWS\\nSkip to main content\\nClick here to return to Amazon Web Services homepage\\nAbout AWS Contact Us Support   English   My Account  \\nSign In\\nCreate an AWS Account\\n\\n\\nClose\\nProfile\\nYour profile helps improve your interactions with select AWS experiences.\\nLogin\\nClose\\nProfile\\nYour profile helps improve your interactions with select AWS experiences.\\nView profile\\nLog out\\n\\nAmazon Q\\nProducts\\nSolutions\\nPricing\\nDocumentation\\nLearn\\nPartner Network\\nAWS Marketplace\\nCustomer Enablement\\nEvents\\nExplore More\\n\\nClose\\n\\nعربي\\nBahasa Indonesia\\nDeutsch\\nEnglish\\nEspañol\\nFrançais\\nItaliano\\n\\nPortuguês\\n\\n\\nTiếng Việt\\n\\nTürkçe\\nΡусский\\nไทย\\n日本語\\n한국어\\n中文 (简体)\\n中文 (繁體)\\n\\nClose\\n\\nMy Profile\\nSign out of AWS Builder ID\\nAWS Management Console\\nAccount Settings\\nBilling & Cost Management\\nSecurity Credentials\\nAWS Personal Health Dashboard\\n\\nClose\\n\\nSupport Center\\nExpert Help\\nKnowledge Center\\nAWS Support Overview\\nAWS re:Post\\n\\nClick here to return to Amazon Web Services homepage\\n\\n\\nClose\\nProfile\\nYour profile helps improve your interactions with select AWS experiences.\\nLogin\\nClose\\nProfile\\nYour profile helps improve your interactions with select AWS experiences.\\nView profile\\nLog out\\nClose\\nProfile\\nYour profile helps improve your interactions with select AWS experiences.\\nView profile\\nLog out\\nGet Started for Free\\nContact Us\\n\\nProducts\\nSolutions\\nPricing\\nIntroduction to AWS\\nGetting Started\\nDocumentation\\nTraining and Certification\\nDeveloper Center\\nCustomer Success\\nPartner Network\\nAWS Marketplace\\nSupport\\nAWS re:Post\\nLog into Console\\nDownload the Mobile App\\n\\nAnthropic's Claude 3.7 Sonnet is now available in Amazon Bedrock\\nPosted on: Feb 24, 2025\\nAnthropic's Claude 3.7 Sonnet hybrid reasoning model, their most intelligent model to date, is now available in Amazon Bedrock. Claude 3.7 Sonnet represents a significant advancement in AI capabilities, offering both quick responses and extended, step-by-step thinking made visible to the user. This new model includes strong improvements in coding and brings enhanced performance across various tasks, like instruction following, math, and physics.  \\nClaude 3.7 Sonnet introduces a unique approach to AI reasoning by integrating it seamlessly with other capabilities. Unlike traditional models that separate quick responses from those requiring deeper thought, Claude 3.7 Sonnet allows users to toggle between standard and extended thinking modes. In standard mode, it functions as an upgraded version of Claude 3.5 Sonnet. While in extended thinking mode, it employs self-reflection to achieve improved results across a wide range of tasks. Amazon Bedrock users can adjust how long the model thinks, offering a flexible trade-off between speed and answer quality. Additionally, users can control the reasoning budget by specifying a token limit, enabling more precise management of cost.  \\nAnthropic has optimized Claude 3.7 Sonnet for real-world applications that align closely with typical language model use cases, rather than focusing solely on math and computer science competition problems. This approach ensures that the model is well-suited to address the diverse needs of customers across various industries and use cases.  \\nClaude 3.7 Sonnet is now available in Amazon Bedrock in the US East (N. Virginia), US East (Ohio), and US West (Oregon) regions. To get started, visit the Amazon Bedrock console. Integrate it into your applications using the Amazon Bedrock API or SDK. For more information and to learn more read the AWS News Blog and Claude in Bedrock product detail page.\\nSign In to the Console\\nLearn About AWS\\n\\nWhat Is AWS?\\nWhat Is Cloud Computing?\\nAWS Accessibility\\nWhat Is DevOps?\\nWhat Is a Container?\\nWhat Is a Data Lake?\\nWhat is Artificial Intelligence (AI)?\\nWhat is Generative AI?\\nWhat is Machine Learning (ML)?\\nAWS Cloud Security\\nWhat's New\\nBlogs\\nPress Releases\\n\\nResources for AWS\\n\\nGetting Started\\nTraining and Certification\\nAWS Trust Center\\nAWS Solutions Library\\nArchitecture Center\\nProduct and Technical FAQs\\nAnalyst Reports\\nAWS Partners\\n\\nDevelopers on AWS\\n\\nDeveloper Center\\nSDKs & Tools\\n.NET on AWS\\nPython on AWS\\nJava on AWS\\nPHP on AWS\\nJavaScript on AWS\\n\\nHelp\\n\\nContact Us\\nGet Expert Help\\nFile a Support Ticket\\nAWS re:Post\\nKnowledge Center\\nAWS Support Overview\\nLegal\\nAWS Careers\\n\\nCreate an AWS Account\\n\\n\\n\\n\\n\\n\\n\\n\\nAmazon is an Equal Opportunity Employer: Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.\\n\\nLanguage\\nعربي\\nBahasa Indonesia\\nDeutsch\\nEnglish\\nEspañol\\nFrançais\\nItaliano\\nPortuguês\\nTiếng Việt\\nTürkçe\\nΡусский\\nไทย\\n日本語\\n한국어\\n中文 (简体)\\n\\n中文 (繁體)\\n\\n\\nPrivacy\\n\\n|\\nAccessibility\\n|\\nSite Terms\\n|\\nCookie Preferences\\n|\\n© 2024, Amazon Web Services, Inc. or its affiliates. All rights reserved.\\n\\nEnding Support for Internet Explorer\\nGot it\\nAWS support for Internet Explorer ends on 07/31/2022. Supported browsers are Chrome, Firefox, Edge, and Safari. Learn more »\\nGot it\"}, {\"title\": \"Anthropic's Claude 3.7 Sonnet is available on Vertex AI - Google Cloud\", \"url\": \"https://cloud.google.com/blog/products/ai-machine-learning/anthropics-claude-3-7-sonnet-is-available-on-vertex-ai\", \"content\": \"Anthropic’s Claude 3.7 Sonnet is available on Vertex AI | Google Cloud Blog \\\"By making Claude 3.7 Sonnet available through Vertex AI, Google Cloud customers can now apply this transformative technology across their organizations. I love the accuracy of Anthropic’s Claude models and the security and advanced AI tools that Google Cloud provides to utilize these models for our auditing process.” — Sean Otto, Senior Director of Data Science & Analytics at AES Running Claude on Google Cloud’s Vertex AI not only accelerates development projects, it enables us to hardwire security into code before it ships.” — Gunjan Patel, Director of Engineering, Office of the CPO at Palo Alto Networks\", \"score\": 0.76300776, \"raw_content\": \"Published Time: 2025-02-25\\nAnthropic’s Claude 3.7 Sonnet is available on Vertex AI | Google Cloud Blog\\nJump to Content\\nCloud\\nBlog\\nContact sales Get started for free\\nCloud\\nBlog\\n\\nSolutions & technology\\nAI & Machine Learning\\nAPI Management\\nApplication Development\\nApplication Modernization\\nChrome Enterprise\\nCompute\\nContainers & Kubernetes\\nData Analytics\\nDatabases\\nDevOps & SRE\\nMaps & Geospatial\\nSecurity\\nSecurity & Identity\\nThreat Intelligence\\n\\n\\nInfrastructure\\nInfrastructure Modernization\\nNetworking\\nProductivity & Collaboration\\nSAP on Google Cloud\\nStorage & Data Transfer\\nSustainability\\n\\n\\nEcosystem\\nIT Leaders\\nIndustries\\nFinancial Services\\nHealthcare & Life Sciences\\nManufacturing\\nMedia & Entertainment\\nPublic Sector\\nRetail\\nSupply Chain\\nTelecommunications\\n\\n\\nPartners\\nStartups & SMB\\nTraining & Certifications\\nInside Google Cloud\\nGoogle Cloud Next & Events\\nGoogle Cloud Consulting\\nGoogle Maps Platform\\nGoogle Workspace\\n\\n\\nDevelopers & Practitioners\\nTransform with Google Cloud\\n\\nContact sales Get started for free\\nAI & Machine Learning\\nAnnouncing Claude 3.7 Sonnet, Anthropic’s first hybrid reasoning model, is available on Vertex AI\\n=====================================================================================================\\nFebruary 24, 2025\\n\\n\\n\\n\\n\\n\\n\\nNenshad Bardoliwalla\\nDirector, Product Management, Vertex AI\\nJoin us at Google Cloud Next\\nApril 9-11 in Las Vegas\\nRegister\\nToday, we’re announcing Claude 3.7 Sonnet, Anthropic’s most intelligent model to date and the first hybrid reasoning model on the market, is available in preview on Vertex AI Model Garden. Claude 3.7 Sonnet can produce quick responses or extended, step-by-step thinking that is made visible to the user. Claude 3.7 Sonnet includes improvements in coding, and is optimized for real-world, practical use cases to reflect customers’ needs.\\n\\\"Claude 3.7 Sonnet represents an exciting breakthrough as the first hybrid reasoning model, combining rapid responses and reasoning in a single model,\\\" said Kate Jensen, Head of Revenue at Anthropic. \\\"By making Claude 3.7 Sonnet available through Vertex AI, Google Cloud customers can now apply this transformative technology across their organizations. Whether developing complex software solutions, delivering customer experiences, or conducting strategic analysis, Claude on Vertex AI helps teams to tackle their most challenging business problems with enterprise-grade reliability.\\\"\\nWe’re also announcing Vertex AI support for Anthropic’s new agentic coding tool, Claude Code. Claude Code lets developers delegate coding tasks to Claude directly from their terminal and is available through Anthropic's limited research preview. For more information on Claude 3.7 Sonnet and Claude Code, including how to access Claude Code, check out Anthropic’s blog here.\\nBuild on a unified AI platform with Vertex AI\\nTo explore the full potential of foundational models like Claude, you’ll need advanced development tools and enterprise-grade reliability to use them in your applications. That’s what you get with Vertex AI, which is built on Google’s AI-optimized infrastructure, stringent security, and learnings from serving 300+ real-world use cases.\\nVertex AI empowers you to take your Claude-powered applications from concept to production on a unified platform. With Vertex AI’s Model-as-a-Service (MaaS) offering, you benefit from simplified procurement, fully managed infrastructure, enterprise-grade security, and advanced developer tools.\\n\\nConfidently deploy agents in production: Power production-grade AI agents with Claude 3.7 Sonnet, using Vertex AI’s full suite of agentic tools and services, including RAG Engine and Agent Engine (coming soon). \\nOptimize performance with fully managed infrastructure: Simplify how you deploy and scale Claude 3.7 Sonnet with Vertex AI’s fully managed infrastructure that’s tailored for AI workloads.\\nAccelerate development with powerful MLOps tools: Explore and evaluate Claude 3.7 Sonnet with fully integrated platform tools like Vertex AI Evaluation for model testing and evaluation and the LangChain integration for custom application building.\\nBuild with enterprise-grade security, compliance, and data governance: Leverage Google Cloud's robust built-in security, privacy, and compliance measures to securely scale your applications. Enterprise controls, such as Vertex AI Model Garden’s organization policy, provide the right access controls to make sure only approved models can be accessed.\\n\\nAdditional features to make the most of Claude on Vertex AI\\nTo enhance your interaction and deployment of Claude models on Vertex AI, including Claude 3.7 Sonnet, we also offer advanced features designed to reduce latency and costs, increase throughput, and optimize Claude model utilization:\\n\\n\\nCount tokens (generally available): Make more informed decisions about your prompts and usage by determining the number of tokens in a message before sending it to Claude. Learn more on how to use count tokens with Claude models and which models are supported here.\\n\\n\\nCitations (generally available): Verify sources with detailed references to the exact sentences and passages it uses to generate responses, leading to more verifiable, trustworthy outputs. Claude 3.7 Sonnet, upgraded Claude 3.5 Sonnet, and Claude 3.5 Haiku support Citations.\\n\\n\\nBatch predictions (preview): Process large volumes of requests asynchronously for cost savings. Popular applications include analyzing large datasets—such as customer databases—for risk assessment or fraud detection, and applications that require periodic updates—such as generating daily reports. Each batch job is processed in less than 24 hours and costs 50% less than standard Anthropic API calls. Learn more on how to use batch predictions with Claude models and which models are supported here.\\n\\n\\nPrompt caching (preview): Provide Claude with more background knowledge and example outputs to improve response accuracy—all while reducing costs. You can cache all or specific parts of your frequently used inputs, so that subsequent queries can use the cached results. Learn more on how to use prompt caching with Claude models and which models are supported here.\\n\\n\\nWe’re also excited to share that Claude 3.5 Haiku, which is already available on Vertex AI Model Garden, now supports multi-modal image input. Claude 3.5 Haiku is Anthropic’s fastest and most cost-effective model.\\nCustomers are driving business results with Anthropic on Google Cloud\\nAES, a global energy company, uses Claude on Vertex AI to significantly increase the accuracy and speed of the company’s health and safety audits:\\n“Our auditors previously spent 14 days completing each audit process. Now, with our Claude-powered agents on Vertex AI, the same work is completed in just one hour. I love the accuracy of Anthropic’s Claude models and the security and advanced AI tools that Google Cloud provides to utilize these models for our auditing process.” — Sean Otto, Senior Director of Data Science & Analytics at AES\\nPalo Alto Networks, a global cybersecurity company, is accelerating software development and security by deploying Anthropic’s Claude models on Vertex AI:\\n“With Claude running on Vertex AI, we saw a 20% to 30% increase in feature development and code implementation. Running Claude on Google Cloud’s Vertex AI not only accelerates development projects, it enables us to hardwire security into code before it ships.” — Gunjan Patel, Director of Engineering, Office of the CPO at Palo Alto Networks\\nQuora, the global knowledge-sharing platform, is harnessing Claude's capabilities on Vertex AI to facilitate millions of daily interactions through Quora’s own AI-powered chat platform, Poe:\\n\\\"We consistently hear from our users about how much they enjoy the intelligence, adaptability, and natural conversational abilities of Anthropic's Claude models. They're relying on these qualities for a wide variety of tasks, from the complex to the creative. By leveraging Claude with Vertex AI's secure and scalable platform, we're able to facilitate millions of daily interactions, ensuring both speed and reliability.\\\" — Spencer Chan, Product Lead at Poe by Quora\\nReplit, a platform for software development and deployment, leverages Claude on Vertex AI to power Replit Agent, which empowers people across the world to use natural language prompts to turn their ideas into applications, regardless of coding experience.\\n“Our AI agent is made more powerful through Anthropic’s Claude models running on Vertex AI. This integration allows us to easily connect with other Google Cloud services, like Cloud Run, to work together behind the scenes to help customers turn their ideas into apps.” — Amjad Masad, Founder and CEO of Replit\\nGet started\\n\\n\\nSelect the Claude 3.7 Sonnet model card in Vertex AI Model Garden. You can also find and easily procure Claude 3.7 Sonnet on Google Cloud Marketplace and take advantage of the ability to draw down on your Google Cloud spend commitments.\\n\\n\\nSelect “Enable” and follow the proceeding instructions.\\n\\n\\nExplore our sample notebook and documentation to start building.\\n\\n\\nPosted in\\n\\nAI & Machine Learning\\n\\nRelated articles\\n AI & Machine Learning ### Optimizing image generation pipelines on Google Cloud: A practical guide By Gopala Dhar • 5-minute read\\n DevOps & SRE ### An SRE’s guide to optimizing ML systems with MLOps pipelines By Max Saltonstall • 5-minute read\\n AI & Machine Learning ### Unlock Inference-as-a-Service with Cloud Run and Vertex AI By Jason (Jay) Smith • 4-minute read\\n Telecommunications ### Rethinking 5G: The cloud imperative By Eric Parsons • 4-minute read\\nFooter Links\\nFollow us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGoogle Cloud\\nGoogle Cloud Products\\nPrivacy\\nTerms\\n\\nCookies management controls\\n\\n\\nHelp\\n*\\n\\n\"}]12\n",
      "2023년 월호\n",
      "\n",
      "SPRi AI Brief |\n",
      "2023-12월호\n",
      "EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항\n",
      "KEY Contents\n",
      "n 유럽의회, EU 집행위원회, EU 이사회가 진행 중인 AI 법 최종협상에서 프랑스, 이탈리아,\n",
      "독일이 기반모델에 대한 규제에 반대하며 협상이 난관에 봉착\n",
      "n 프랑스, 이탈리아, 독일 3개국은 기반모델 개발기업에 대하여 자율적 행동강령을 도입하고\n",
      "준수를 의무화하는 방안을 제안\n",
      "£AI 법 3자 협상, 이사회 일부 국가가 기반모델 규제에 반대하며 차질\n",
      "\n",
      "n 3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4가 최고의 성능을 기록했으며, GPT-3.5 터보도\n",
      "GPT-4와 거의 동등한 성능을 발휘\n",
      "∙ 메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴\n",
      "형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅\n",
      "페이스의 제퍼(Zephyr-7b)가 라마2를 능가\n",
      "<갈릴레오의 LLM 환각 지수(RAG 포함 질문과 답변 기준)>\n",
      "\n",
      "<갈릴레오의 LLM 환각 지수(RAG 포함 질문과 답변 기준)>\n",
      "☞ 출처: Galileo, LLM Hallucination Index, 2023.11.15.\n",
      "\n",
      "프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\n",
      "☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.\n",
      "Gov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit\n",
      "concludes, 2023.11.02.\n",
      "\n",
      "£예술가들의 AI 저작권 침해 소송, 저작권 미등록과 증거불충분으로 기각\n",
      "n 미국 캘리포니아 북부지방법원의 윌리엄 오릭(William Orrick) 판사는 2023년 10월 30일 미드저니\n",
      "(Midjourney), 스태빌리티AI(Stability AI), 디비언트아트(DeviantArt)에 제기된 저작권 침해 소송을 기각\n",
      "∙ 2023년 1월 예술가 사라 앤더슨(Sarah Anderson), 캘리 맥커넌(Kelly McKernan), 칼라\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Claude 3.7 Sonnet은 Anthropic에서 개발한 AI 모델로, 최초의 하이브리드 추론 모델로 알려져 있습니다. 이 모델은 빠른 응답과 깊이 있는 분석적 사고를 하나의 시스템에서 결합하여 제공합니다. Claude 3.7 Sonnet은 이전 모델인 Claude 3.5 Sonnet에 비해 속도, 추론 능력 및 실제 업무 수행 능력에서 큰 향상을 보여주며, 특히 코딩 및 소프트웨어 엔지니어링 작업에서 우수한 성능을 발휘합니다.\n",
      "\n",
      "Claude 3.7 Sonnet의 주요 특징은 \"확장된 사고\" 모드로, 사용자가 빠른 응답과 자세한 분석적 사고 중에서 선택할 수 있게 해줍니다. 이 모델은 특히 코딩, 문제 해결, 고객 지원, 콘텐츠 검토, 법률 문서 요약 등 다양한 실제 업무에 최적화되어 있으며, Amazon Bedrock과 Google Cloud의 Vertex AI 플랫폼에서 사용할 수 있습니다.\n",
      "\n",
      "Claude 3.7 Sonnet은 API를 통해 사용자가 필요한 만큼의 추론 과정을 설정할 수 있는 기능을 제공하여, 속도와 응답의 품질을 사용자가 조절할 수 있도록 합니다. 이 모델은 특히 소프트웨어 개발, 고객 지원 자동화, 법률 요약 등의 분야에서 강력한 성능을 발휘하며, 다양한 산업과 사용 사례에 적합한 모델로 평가받고 있습니다."
     ]
    }
   ],
   "source": [
    "# 그래프 스트림\n",
    "stream_graph(\n",
    "    simple_react_agent,\n",
    "    {\"messages\": [(\"human\", \"claude 3.7 sonnet 관련 정보를 검색해줘\")]},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**추적**: https://smith.langchain.com/public/e28f6b6c-463c-4211-8a75-3c88dfdcc41c/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. 멀티턴 대화를 위한 단기 메모리: `checkpointer`\n",
    "\n",
    "단기 메모리 기능이 없는 그래프는 이전 대화를 기억하지 못합니다.\n",
    "\n",
    "즉, 멀티턴 대화를 지원하지 않는다는 말이기도 합니다. 따라서, 다음과 같이 이전 대화를 기억하지 못합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "안녕하세요, 테디님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림\n",
    "stream_graph(\n",
    "    simple_react_agent,\n",
    "    {\"messages\": [(\"human\", \"안녕, 반가워! 내 이름은 테디야!\")]},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "죄송하지만, 저는 사용자님의 이름을 알 수 없습니다."
     ]
    }
   ],
   "source": [
    "# 그래프 스트림\n",
    "stream_graph(simple_react_agent, {\"messages\": [(\"human\", \"내 이름이 뭐라고?\")]}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MemorySaver`\n",
    "\n",
    "LangGraph 는 `Checkpointer` 를 사용해 각 단계가 끝난 후 그래프 상태를 자동으로 저장할 수 있습니다.\n",
    "\n",
    "이 내장된 지속성 계층은 메모리를 제공하여 LangGraph가 마지막 상태 업데이트에서 선택할 수 있도록 합니다. \n",
    "\n",
    "가장 사용하기 쉬운 체크포인터 중 하나는 그래프 상태를 위한 인메모리 키-값 저장소인 `MemorySaver`입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 메모리 설정\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# ReAct Agent 생성(checkpointer 설정)\n",
    "simple_react_agent = create_react_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    checkpointer=memory,\n",
    "    prompt=\"You are a helpful assistant. Answer in Korean.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "안녕하세요, 테디! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?"
     ]
    }
   ],
   "source": [
    "# Config 설정\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# 그래프 스트림\n",
    "stream_graph(\n",
    "    simple_react_agent,\n",
    "    {\"messages\": [(\"human\", \"안녕, 반가워! 내 이름은 테디야!\")]},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 이전 대화 내용을 잘 기억하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "당신의 이름은 테디입니다!"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림\n",
    "stream_graph(simple_react_agent, {\"messages\": [(\"human\", \"내 이름이 뭐라고?\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "죄송하지만, 당신의 이름은 알 수 없습니다. 대화 중에 이름을 제공해 주시면 기억하겠습니다."
     ]
    }
   ],
   "source": [
    "# llm 메모리는 thread_id 별로 저장하기때문에 thread_id 를 abc123 ->abc124로 바꾸면 기억못함\n",
    "config = {\"configurable\": {\"thread_id\": \"abc124\"}}\n",
    "stream_graph(simple_react_agent, {\"messages\": [(\"human\", \"내 이름이 뭐라고?\")]}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**추적**: https://smith.langchain.com/public/16105167-e6db-4e26-add8-96cbf53191f7/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. LangGraph 워크플로우 구현\n",
    "\n",
    "이전의 `create_react_agent` 를 사용하여 에이전트를 구현해 보았습니다.\n",
    "\n",
    "하지만, 이전의 에이전트는 단일 에이전트 형태이기 때문에 복잡한 워크플로우를 구현하기 어렵습니다.\n",
    "\n",
    "이를 해결하기 위해서는 워크플로우를 구현해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "1. State 정의(TypedDict 형식으로 정의)\n",
    "2. 노드 정의(함수로 구현)\n",
    "3. 그래프 생성(StateGraph 클래스 사용)\n",
    "4. 컴파일(checkpointer 설정)\n",
    "5. 실행\n",
    "\n",
    "### State 정의\n",
    "\n",
    "`State`: Graph 의 노드와 노드 간 공유하는 상태를 정의합니다.\n",
    "\n",
    "일반적으로 `TypedDict` 형식을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# GraphState 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"User's Question\"]  # 질문\n",
    "    documents: Annotated[str, \"Retrieved Documents\"]  # 문서의 검색 결과\n",
    "    answer: Annotated[str, \"LLM generated answer\"]  # 답변\n",
    "    messages: Annotated[list, add_messages]  # 메시지(누적되는 list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노드(Node) 정의\n",
    "\n",
    "- `Nodes`: 각 단계를 처리하는 노드입니다. 보통은 Python 함수로 구현합니다. 입력과 출력이 상태(State) 값입니다.\n",
    "  \n",
    "**참고**  \n",
    "\n",
    "- `State`를 입력으로 받아 정의된 로직을 수행한 후 업데이트된 `State`를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.utils import format_docs\n",
    "\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "\n",
    "    # 검색된 문서를 형식화합니다.(프롬프트 입력으로 넣어주기 위함)\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return {\"documents\": retrieved_docs}\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 검색된 문서를 상태에서 가져옵니다.\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 체인을 호출하여 답변을 생성합니다.\n",
    "    response = pdf_chain.invoke({\"question\": latest_question, \"context\": documents})\n",
    "    # 생성된 답변, (유저의 질문, 답변) 메시지를 상태에 저장합니다.\n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"messages\": [(\"user\", latest_question), (\"assistant\", response)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 생성\n",
    "\n",
    "- `StateGraph`: `State` 를 입력으로 받아 `Node` 를 실행하고 `State` 를 업데이트하는 그래프 생성 클래스.\n",
    "- `Edges`: 현재 `State`를 기반으로 다음에 실행할 `Node`를 결정.\n",
    "- `set_entry_point`: 그래프 진입점 설정.\n",
    "- `compile`: 그래프 컴파일."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 생성\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "\n",
    "# 엣지 정의\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")  # 검색 -> 답변\n",
    "workflow.add_edge(\"llm_answer\", END)  # 답변 -> 종료\n",
    "\n",
    "# 그래프 진입점(entry_point) 설정\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 체크포인터 설정\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 컴파일\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일이 완료된 그래프를 실행하고 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프 실행\n",
    "\n",
    "- `config` 파라미터는 그래프 실행 시 필요한 설정 정보를 전달합니다.\n",
    "- `recursion_limit`: 그래프 실행 시 재귀 최대 횟수를 설정합니다.\n",
    "- `inputs`: 그래프 실행 시 필요한 입력 정보를 전달합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 메시지 출력 스트리밍은 [LangGraph 스트리밍 모드의 모든 것](https://wikidocs.net/265770) 을 참고해주세요.\n",
    "\n",
    "아래의 `stream_graph` 함수는 특정 노드만 스트리밍 출력하는 함수입니다.\n",
    "\n",
    "손쉽게 특정 노드의 스트리밍 출력을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의하였으며, 이 중 5억 달러를 우선 투자했습니다. 아마존은 앤스로픽에 최대 40억 달러의 투자 계획을 발표했습니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 14)"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = {\"configurable\": {\"resursion_limit\": 10, \"thread_id\": random_uuid()}}\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\"question\": \"앤스로픽에 투자한 기업과 투자금액을 알려주세요.\"}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추적: https://smith.langchain.com/public/1aa445e0-672e-4f15-9253-1c8efcdb1355/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.Routing\n",
    "\n",
    "LLM 애플리케이션에서 라우팅은 입력 쿼리나 상태에 따라 적절한 처리 경로나 구성 요소로 요청을 전달하는 메커니즘입니다. \n",
    "\n",
    "LangChain/LangGraph에서 라우팅은 특정 작업에 가장 적합한 모델이나 도구를 선택하고, 복잡한 워크플로우를 관리하며, 비용과 성능 균형을 최적화하는 데 필수적입니다. \n",
    "\n",
    "**Agent**\n",
    "- 도구 선택을 하는 방식으로 라우팅\n",
    "- 따라서, 도우에 대한 description 이 상세하게 작성되어야 합니다.\n",
    "\n",
    "**LLM.with_structured_output**\n",
    "- Function Calling 을 사용하는 방식으로 라우팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 사용자 쿼리를 가장 관련성 높은 데이터 소스로 라우팅하는 데이터 모델\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    # 데이터 소스 선택을 위한 리터럴 타입 필드 \n",
    "    ## 중요! 대신 datasource를 설정하면 반드시 두 에이전트를 수행. \n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to `web_search` or a `vectorstore`.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# llm 구조화된 출력 설정\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 프롬프트 설정  (상황에 따라 어떤 걸 수행하도록하는지 프롬프트)\n",
    "## !도구의 프롬프트 다른점 \n",
    "### 도구 프롬프트 : 자기 써달라고 어필하는 프롬프트\n",
    "### 아래 시스템 프롬프트 : 전체 아키텍쳐 기반으로 조율하는 프롬프트 (도구를 적절히 고름)\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to AI Brief Report(SPRI) including Samsung Gause, Anthropic, etc.\n",
    "Use the vectorstore for questions on AI related topics. Otherwise, use `web_search`.\"\"\"\n",
    "\n",
    "# Routing 을 위한 프롬프트 템플릿 생성\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 라우터를 결합하여 질문 라우터 생성\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쿼리를 실행한 뒤 호출 결과의 차이를 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(datasource='vectorstore')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 실행\n",
    "question_router.invoke(\"삼성전자가 만든 생성형 AI 이름을 찾아줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 실행\n",
    "question_router.invoke(\"LangCon2025 이벤트의 날짜와 장소는?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 `retrieve`, `generate`, `web_search` 노드를 구현한 코드입니다.\n",
    "\n",
    "- `retrieve`: 문서 검색 노드\n",
    "- `generate`: 답변 생성 노드\n",
    "- `web_search`: 웹 검색 노드\n",
    "\n",
    "이 노드들을 사용하여 워크플로우를 구현합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve(state):\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 문서 검색 수행\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "\n",
    "    # 검색된 문서 반환\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def generate(state):\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG 답변 생성\n",
    "    generation = pdf_chain.invoke({\"context\": documents, \"question\": question})\n",
    "\n",
    "    # 생성된 답변 반환\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "# 웹 검색 노드\n",
    "def web_search(state):\n",
    "    # print(\"==== [WEB SEARCH] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 웹 검색 수행\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "    # 검색된 문서 반환\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "    return {\"documents\": web_results_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문 라우팅 노드의 구현입니다.\n",
    "\n",
    "사용자의 질문에 대해 `question_router` 를 호출하여 적절한 데이터 소스로 라우팅합니다.\n",
    "\n",
    "- `web_search`: 웹 검색\n",
    "- `vectorstore`: 벡터 스토어\n",
    "\n",
    "라우팅 결과에 따라 적절한 노드로 라우팅합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 라우팅 노드\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # 질문 가져오기\n",
    "    question = state[\"question\"]\n",
    "    # 질문 라우팅\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # 질문 라우팅 결과에 따른 노드 라우팅\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"\\n==== [GO TO WEB SEARCH] ====\")\n",
    "        return \"need to search web\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"\\n==== [GO TO VECTORSTORE] ====\")\n",
    "        return \"search on DB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 생성\n",
    "\n",
    "이 단계에서는 `web_search`, `retrieve`, `generate` 노드를 생성하고, 이들을 연결하는 조건부 엣지를 추가합니다.\n",
    "\n",
    "- `web_search`: 웹 검색 노드\n",
    "- `retrieve`: 문서 검색 노드\n",
    "- `generate`: 답변 생성 노드\n",
    "\n",
    "조건부 엣지: 질문 라우팅 노드에서 반환된 결과에 따라 적절한 노드로 라우팅합니다.\n",
    "\n",
    "- `need to search web`: 웹 검색 노드로 라우팅\n",
    "- `search on DB`: 벡터 스토어 노드로 라우팅\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 상태 초기화\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"web_search\", web_search)  # 웹 검색\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 문서 검색\n",
    "workflow.add_node(\"generate\", generate)  # 답변 생성\n",
    "\n",
    "# 그래프 빌드\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"need to search web\": \"web_search\",  # 웹 검색으로 라우팅\n",
    "        \"search on DB\": \"retrieve\",  # 벡터스토어로 라우팅\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")  # 문서 검색 후 답변 생성\n",
    "workflow.add_edge(\"web_search\", \"generate\")  # 웹 검색 후 답변 생성\n",
    "workflow.add_edge(\"generate\", END)  # 답변 생성 후 종료\n",
    "\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행하고 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"resursion_limit\": 10, \"thread_id\": \"123\"}}\n",
    "\n",
    "stream_graph(\n",
    "    app, {\"question\": \"앤스로픽에 투자한 기업과 투자금액을 알려주세요.\"}, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"resursion_limit\": 10, \"thread_id\": \"123\"}}\n",
    "\n",
    "stream_graph(\n",
    "    app,\n",
    "    {\"question\": \"Claude 3.7 sonnet 관련 최신 뉴스를 검색해줘. 한글로 답변해줘\"},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5.Fan-out / Fan-in\n",
    "\n",
    "LangGraph에서 Fan-out/Fan-in은 복잡한 LLM 워크플로우 관리를 위한 중요한 패턴입니다.\n",
    "\n",
    "Fan-out은 단일 입력을 여러 병렬 작업으로 분배하는 패턴으로, 하나의 프롬프트나 쿼리를 여러 LLM, 도구, 또는 처리 단계로 동시에 전송하여 다양한 관점이나 접근 방식을 얻을 수 있게 합니다. 이는 복잡한 문제를 더 작고 전문화된 하위 작업으로 분할하거나 동일한 작업에 대해 여러 모델의 결과를 비교할 때 유용합니다.\n",
    "\n",
    "Fan-in은 Fan-out의 역과정으로, 여러 병렬 작업의 결과를 단일 출력이나 다음 단계로 통합합니다. 이는 다양한 모델이나 도구에서 생성된 결과를 종합하여 더 완전하고 정확한 최종 응답을 만들거나 여러 에이전트의 작업을 조정할 때 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# 상태 정의(add_messages 리듀서 사용)\n",
    "class State(TypedDict):\n",
    "    aggregate: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# 노드 값 반환 클래스\n",
    "class ReturnNodeValue:\n",
    "    # 초기화\n",
    "    def __init__(self, node_secret: str):\n",
    "        self._value = node_secret\n",
    "\n",
    "    # 호출시 상태 업데이트\n",
    "    def __call__(self, state: State) -> Any:\n",
    "        print(f\"Adding {self._value} to {state['aggregate']}\")\n",
    "        return {\"aggregate\": [self._value]}\n",
    "\n",
    "\n",
    "# 상태 그래프 초기화\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# 노드 A부터 D까지 생성 및 값 할당\n",
    "builder.add_node(\"a\", ReturnNodeValue(\"I'm A\"))\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"I'm B\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"I'm C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"I'm D\"))\n",
    "\n",
    "# 노드 연결\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"d\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "result = graph.invoke({\"aggregate\": []}, {\"configurable\": {\"thread_id\": \"foo\"}})\n",
    "print(\"===\" * 30)\n",
    "print(result[\"aggregate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일부만 Fan-out 하는 방법\n",
    "\n",
    "(Fan-out 의 순서 조정)\n",
    "\n",
    "조건부 엣지를 두어 일부만 Fan-out 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "\n",
    "# 상태 정의(add_messages 리듀서 사용)\n",
    "class State(TypedDict):\n",
    "    aggregate: Annotated[list, add_messages]\n",
    "    which: str\n",
    "\n",
    "\n",
    "# 노드별 고유 값을 반환하는 클래스\n",
    "class ReturnNodeValue:\n",
    "    def __init__(self, node_secret: str):\n",
    "        self._value = node_secret\n",
    "\n",
    "    def __call__(self, state: State) -> Any:\n",
    "        print(f\"Adding {self._value} to {state['aggregate']}\")\n",
    "        return {\"aggregate\": [self._value]}\n",
    "\n",
    "\n",
    "# 상태 그래프 초기화\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"a\", ReturnNodeValue(\"I'm A\"))\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"I'm B\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"I'm C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"I'm D\"))\n",
    "builder.add_node(\"e\", ReturnNodeValue(\"I'm E\"))\n",
    "\n",
    "\n",
    "# 상태의 'which' 값에 따른 조건부 라우팅 경로 결정 함수\n",
    "def route_bc_or_cd(state: State) -> Sequence[str]:\n",
    "    if state[\"which\"] == \"cd\":\n",
    "        return [\"c\", \"d\"]\n",
    "    elif state[\"which\"] == \"bc\":\n",
    "        return [\"b\", \"c\"]\n",
    "    else:\n",
    "        return [\"b\", \"c\", \"d\"]\n",
    "\n",
    "\n",
    "# 전체 병렬 처리할 노드 목록\n",
    "intermediates = [\"b\", \"c\", \"d\"]\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"a\",\n",
    "    route_bc_or_cd,\n",
    "    intermediates,\n",
    ")\n",
    "for node in intermediates:\n",
    "    builder.add_edge(node, \"e\")\n",
    "\n",
    "\n",
    "# 최종 노드 연결 및 그래프 컴파일\n",
    "builder.add_edge(\"e\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행(which: bc 로 지정)\n",
    "result = graph.invoke({\"aggregate\": [], \"which\": \"bc\"})\n",
    "print(\"===\" * 30)\n",
    "print(result[\"aggregate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행(which: cd 로 지정)\n",
    "result = graph.invoke({\"aggregate\": [], \"which\": \"cd\"})\n",
    "print(\"===\" * 30)\n",
    "print(result[\"aggregate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6.대화 기록 요약을 추가하는 방법\n",
    "\n",
    "대화 기록을 유지하는 것은 **지속성**의 가장 일반적인 사용 사례 중 하나입니다. 이는 대화를 지속하기 쉽게 만들어주는 장점이 있습니다. \n",
    "\n",
    "하지만 대화가 길어질수록 대화 기록이 누적되어 `context window`를 더 많이 차지하게 됩니다. 이는 `LLM` 호출이 더 비싸고 길어지며, 잠재적으로 오류가 발생할 수 있어 바람직하지 않을 수 있습니다. 이를 해결하기 위한 한 가지 방법은 현재까지의 대화 요약본을 생성하고, 이를 최근 `N` 개의 메시지와 함께 사용하는 것입니다. \n",
    "\n",
    "이 가이드에서는 이를 구현하는 방법의 예시를 살펴보겠습니다.\n",
    "\n",
    "다음과 같은 단계가 필요합니다.\n",
    "\n",
    "- 대화가 너무 긴지 확인 (메시지 수나 메시지 길이로 확인 가능)\n",
    "- 너무 길다면 요약본 생성 (이를 위한 프롬프트 필요)\n",
    "- 마지막 `N` 개의 메시지를 제외한 나머지 삭제\n",
    "\n",
    "이 과정에서 중요한 부분은 오래된 메시지를 삭제(`DeleteMessage`) 하는 것입니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, RemoveMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# 대화 및 요약을 위한 모델 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "# 메시지 상태와 요약 정보를 포함하는 상태 클래스\n",
    "class State(MessagesState):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM 답변 생성 노드를 구현합니다. 여기서 이전의 대화요약 내용이 있다면 이를 입력에 포함합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: State):\n",
    "    # 이전 요약 정보 확인\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 이전 요약 정보가 있다면 시스템 메시지로 추가\n",
    "    if summary:\n",
    "        # 시스템 메시지와 이전 메시지 결합\n",
    "        messages = [\n",
    "            SystemMessage(content=f\"Summary of conversation earlier: {summary}\")\n",
    "        ] + state[\"messages\"]\n",
    "    else:\n",
    "        # 이전 메시지만 사용\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    # 모델 호출\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # 응답 반환\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약이 필요한 상황인지를 판단합니다.\n",
    "\n",
    "여기서는 메시지 수가 6개 초과라면 요약 노드로 이동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "\n",
    "# 대화 종료 또는 요약 결정 로직\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    # 메시지 목록 확인\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 메시지 수가 6개 초과라면 요약 노드로 이동\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약 노드를 구현합니다. 이전 요약 정보가 있다면 이를 입력에 포함하고, 없다면 새로운 요약 메시지를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 내용 요약 및 메시지 정리 로직\n",
    "def summarize_conversation(state: State):\n",
    "    # 이전 요약 정보 확인\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 이전 요약 정보가 있다면 요약 메시지 생성\n",
    "    if summary:\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above in Korean.\"\n",
    "        )\n",
    "    else:\n",
    "        # 요약 메시지 생성\n",
    "        summary_message = \"Create a summary of the conversation above in Korean:\"\n",
    "\n",
    "    # 요약 메시지와 이전 메시지 결합\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    # 모델 호출\n",
    "    response = model.invoke(messages)\n",
    "    # 오래된 메시지 삭제\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    # 요약 정보 반환\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프 생성 및 컴파일\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 그래프 초기화\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 대화 및 요약 노드 추가\n",
    "workflow.add_node(\"conversation\", generate)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# 시작점을 대화 노드로 설정\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "\n",
    "# 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\n",
    "    \"conversation\",\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# 요약 노드에서 종료 노드로의 엣지 추가\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# 워크플로우 컴파일 및 메모리 체크포인터 설정\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 메시지 출력을 위한 함수를 구현(헬퍼 함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_user_message(message):\n",
    "    print(\"\\n==================================================\\n\\n😎\", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화를 시작합니다. 우선 6개의 대화를 채워보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지 핸들링을 위한 HumanMessage 클래스 임포트\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 스레드 ID가 포함된 설정 객체 초기화\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"resursion_limit\": 10}}\n",
    "\n",
    "# 첫 번째 메시지\n",
    "print_user_message(\"안녕하세요? 반갑습니다. 제 이름은 테디입니다.\")\n",
    "stream_graph(\n",
    "    app,\n",
    "    {\"messages\": [(\"human\", \"안녕하세요? 반갑습니다. 제 이름은 테디입니다.\")]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "# 두 번째 메시지\n",
    "print_user_message(\"제 이름이 뭔지 기억하세요?\")\n",
    "stream_graph(app, {\"messages\": [(\"human\", \"제 이름이 뭔지 기억하세요?\")]}, config)\n",
    "\n",
    "# 세 번째 메시지\n",
    "print_user_message(\"제 취미는 Netflix 시리즈를 보는 것입니다.\")\n",
    "stream_graph(\n",
    "    app, {\"messages\": [(\"human\", \"제 취미는 Netflix 시리즈를 보는 것입니다.\")]}, config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 확인합니다. 6개 대화를 했으므로, 요약본이 만들어 져야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 구성 값 검색\n",
    "values = app.get_state(config).values\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 추가로 대화를 입력하여 요약본을 기반으로 잘 답변하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네 번째 메시지\n",
    "print_user_message(\"제 취미가 뭐라고 했나요?\")\n",
    "stream_graph(app, {\"messages\": [(\"human\", \"제 취미가 뭐라고 했나요?\")]}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추적: https://smith.langchain.com/public/c0f62f0b-74b5-4dc3-bd1c-3e474a0dbef9/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7. Human in the Loop\n",
    "\n",
    "LLM 애플리케이션에서 Human-in-the-loop 은 자동화된 AI 시스템과 인간의 개입 및 판단을 결합하는 접근 방식입니다. \n",
    "\n",
    "이 방식에서는 AI 시스템이 초기 처리와 분석을 수행하지만, 불확실하거나 중요한 결정이 필요한 시점에서 인간 전문가의 개입을 요청합니다. \n",
    "\n",
    "Human-in-the-loop 은 높은 정확도가 필요한 복잡한 상황, 윤리적 판단이 필요한 경우, 또는 AI의 신뢰도가 낮은 결과에 대해 검증이 필요할 때 특히 중요합니다.\n",
    "\n",
    "`from langgraph.types import interrupt`\n",
    "\n",
    "`interrupt` 함수는 인간의 개입을 요청하는 데 사용됩니다. 이 함수는 인간의 입력을 받아 처리하고, 결과를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "import uuid\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import START\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    evaluation: Annotated[str, \"Evaluation\"]\n",
    "\n",
    "\n",
    "def llm_node(state: State):\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    value = interrupt(\n",
    "        # 사람의 피드백 요청\n",
    "        {\"text_to_revise\": state[\"messages\"][-1]}\n",
    "    )\n",
    "    return {\n",
    "        # 사람의 피드백으로 업데이트\n",
    "        \"messages\": [HumanMessage(content=value)]\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluation_node(state: State):\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "Here is the user's question and the model's response\n",
    "The user's question: {state[\"messages\"][0]}\n",
    "Model's response: {state[\"messages\"][-1]}\n",
    "\n",
    "Please rate whether the model's response accurately answered your question.\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"evaluation\": response}\n",
    "\n",
    "\n",
    "# 그래프 생성\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"llm\", llm_node)\n",
    "workflow.add_node(\"human\", human_node)\n",
    "workflow.add_node(\"eval\", evaluation_node)\n",
    "\n",
    "# 엣지 추가\n",
    "workflow.add_edge(START, \"llm\")\n",
    "workflow.add_edge(\"llm\", \"human\")\n",
    "workflow.add_edge(\"human\", \"eval\")\n",
    "workflow.add_edge(\"eval\", END)\n",
    "\n",
    "# 체크포인터 설정\n",
    "checkpointer = MemorySaver()\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기 질문을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 설정\n",
    "config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "\n",
    "stream_graph(app, {\"messages\": [(\"human\", \"2+6=?\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Command` 객체는 인간의 개입을 요청하는 데 사용됩니다. 이 객체는 인간의 입력을 받아 처리하고, 결과를 반환합니다.\n",
    "\n",
    "- `resume`: 피드백을 입력하고 남은 단계를 재게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_graph(app, Command(resume=\"2 + 6 = 9\"), config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (인터럽트) 추적: https://smith.langchain.com/public/c251955b-6999-4983-9a92-6905700333d3/r\n",
    "- (이후) 추적: https://smith.langchain.com/public/c251955b-6999-4983-9a92-6905700333d3/r    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "import uuid\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import START\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.graph import END\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    evaluation: Annotated[str, \"Evaluation\"]\n",
    "\n",
    "\n",
    "def llm_node(state: State):\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def human_approval(state: State) -> Command[Literal[\"llm\", END]]:\n",
    "    is_approved = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            # 답변을 사람에게 보여주고 수정 요청\n",
    "            \"need_to_revise\": state[\"messages\"][-1],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if is_approved:\n",
    "        return Command(\n",
    "            goto=END, update={\"messages\": [HumanMessage(content=\"You are great!\")]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"llm\",\n",
    "            update={\n",
    "                \"messages\": [HumanMessage(content=\"You are wrong.. Please try again\")]\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "# 그래프 생성\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"llm\", llm_node)\n",
    "workflow.add_node(\"human\", human_approval)\n",
    "\n",
    "# 엣지 추가\n",
    "workflow.add_edge(START, \"llm\")\n",
    "workflow.add_edge(\"llm\", \"human\")\n",
    "\n",
    "# 체크포인터 설정\n",
    "checkpointer = MemorySaver()\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 설정\n",
    "config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "\n",
    "stream_graph(app, {\"messages\": [(\"human\", \"1, 2, 4, 10, ?\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_graph(app, Command(resume=False), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8. Long-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**메모리**는 사람들이 현재와 미래를 이해하기 위해 정보를 저장하고, 검색하며 사용하는 인지 기능입니다.\n",
    "\n",
    "AI 애플리케이션에서 사용할 수 있는 [다양한 **장기 메모리 유형**](https://langchain-ai.github.io/langgraph/concepts/memory/#memory)이 있습니다.\n",
    "\n",
    "여기에서는 **장기 기억**을 저장하고 검색하는 방법으로 [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)를 소개합니다.\n",
    "\n",
    "`short-term (within-thread)` 및 `long-term (across-thread)` 메모리를 모두 사용하는 챗봇을 구축할 것입니다.\n",
    "\n",
    "사용자에 대한 사실인 장기 [**semantic memory**](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory)에 중점을 둘 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangGraph Store**\n",
    "\n",
    "[LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) 는 LangGraph에서 *thread 간* 정보를 저장하고 검색할 수 있는 방법을 제공합니다. \n",
    "\n",
    "이 저장소는 지속적인 `key-value` 데이터를 관리하기 위한 [오픈 소스 기본 클래스](https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/)로, 개발자가 자신만의 저장소를 쉽게 구현할 수 있도록 설계되었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# LangGraph의 InMemoryStore 인스턴스 생성\n",
    "persistant_memory = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스토어에 객체(예: 메모리)를 저장할 때는 [Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)에 다음 정보를 제공합니다.\n",
    "\n",
    "- **namespace** (`namespace`): 객체를 구분하는 데 사용되는 튜플 형태의 식별자입니다 (디렉토리와 유사).\n",
    "- **key** (`key`): 객체의 고유 식별자입니다 (파일 이름과 유사).\n",
    "- **value** (`value`): 객체의 실제 내용입니다 (파일 내용과 유사).\n",
    "\n",
    "`namespace`와 `key`를 사용하여 객체를 스토어에 저장하기 위해 [put](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put) 메서드를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장할 메모리의 사용자 ID 설정\n",
    "user_id = \"teddy\"\n",
    "\n",
    "# 사용자 ID와 메모리 구분을 위한 네임스페이스 정의\n",
    "namespace_for_memory = (\"memories\", user_id)\n",
    "\n",
    "# 고유 키 생성을 위한 UUID 생성\n",
    "key = \"user_memory\"\n",
    "\n",
    "# 저장할 메모리 값으로 딕셔너리 정의\n",
    "value = {\n",
    "    \"job\": \"AI Engineer\",\n",
    "    \"location\": \"Seoul, Korea\",\n",
    "    \"hobbies\": [\"Watching Netflix\", \"Coding\"],\n",
    "}\n",
    "\n",
    "# 지정된 네임스페이스에 메모리 저장\n",
    "persistant_memory.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`search`](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search)을 이용하여 `namespace` 기준으로 `store`에서 객체를 검색할 수 있습니다. 이 메서드는 목록을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된 네임스페이스로부터 메모리 객체 검색\n",
    "memories = persistant_memory.search(namespace_for_memory)\n",
    "\n",
    "# 검색된 메모리 객체의 메타데이터를 딕셔너리 형식으로 변환\n",
    "memories[0].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**장기 메모리를 갖춘 챗봇**\n",
    "\n",
    "챗봇은 [두 가지 유형의 메모리](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156)를 갖추어야 합니다.\n",
    "\n",
    "1. `Short-term (within-thread) memory`: 챗봇이 대화 내역을 지속적으로 저장하거나, 대화 세션 중에 중단을 허용할 수 있습니다.\n",
    "2. `Long-term (cross-thread) memory`: 챗봇이 특정 사용자에 대한 정보를 *모든 대화 세션에 걸쳐* 기억할 수 있습니다.\n",
    "\n",
    "이 두 가지 메모리 유형을 통해 챗봇은 사용자와의 대화를 더욱 원활하고 개인화된 방식으로 관리할 수 있습니다. `Short-term memory`는 현재 대화 세션 내에서의 맥락을 유지하는 데 사용되며, `Long-term memory`는 사용자에 대한 지속적인 정보를 저장하여 여러 세션에 걸쳐 일관된 상호작용을 가능하게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 모델 시스템 메시지 정의\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# 새로운 메모리 생성 지침 정의\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"\"You are collecting information about the user to personalize your responses.\n",
    "\n",
    "CURRENT USER INFORMATION:\n",
    "{memory}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Review the chat history below carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, job, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "Based on the chat history below, please update the user information:\"\"\"\n",
    "\n",
    "\n",
    "# call_model 함수 정의\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # 설정에서 사용자 ID 가져오기\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # 스토어에서 메모리 검색\n",
    "    namespace = (\"memories\", user_id)\n",
    "    key = \"user_memory\"\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    # 기존 메모리 내용 추출 및 프리픽스 추가\n",
    "    if existing_memory:\n",
    "        # 값은 메모리 키를 포함하는 딕셔너리\n",
    "        existing_memory_content = existing_memory.value.get(\"memories\")\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # 시스템 프롬프트에 메모리 포맷\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
    "\n",
    "    # 메모리와 대화 기록을 사용하여 응답 생성\n",
    "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# write_memory 함수 정의\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "\n",
    "    # 설정에서 사용자 ID 가져오기\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # 스토어에서 기존 메모리 검색\n",
    "    namespace = (\"memories\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # 메모리 추출\n",
    "    if existing_memory:\n",
    "        existing_memory_content = existing_memory.value.get(\"memories\")\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # 시스템 프롬프트에 메모리 포맷\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "\n",
    "    # 스토어에 기존 메모리 덮어쓰기\n",
    "    key = \"user_memory\"\n",
    "\n",
    "    # 메모리 키를 포함하는 딕셔너리로 값 작성\n",
    "    store.put(namespace, key, {\"memories\": new_memory.content})\n",
    "\n",
    "\n",
    "# 그래프 정의\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"call_model\", call_model)\n",
    "workflow.add_node(\"write_memory\", write_memory)\n",
    "workflow.add_edge(START, \"call_model\")\n",
    "workflow.add_edge(\"call_model\", \"write_memory\")\n",
    "workflow.add_edge(\"write_memory\", END)\n",
    "\n",
    "# 장기 메모리 저장소 설정\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# 단기 메모리 체크포인터 설정\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# 체크포인터 및 스토어를 포함하여 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단기 메모리를 위한 쓰레드 ID 제공(thread_id)\n",
    "# 장기 메모리를 위한 사용자 ID 제공(user_id)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"teddy\"}}\n",
    "\n",
    "# 사용자 입력\n",
    "input_messages = [\n",
    "    HumanMessage(\n",
    "        content=\"안녕 반가워! 내 이름은 테디 입니다. 저의 취미는 코딩 하고 영화 보는 것입니다.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, {\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단기 메모리를 위한 쓰레드 ID 제공(thread_id)\n",
    "# 장기 메모리를 위한 사용자 ID 제공(user_id)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"teddy2\"}}\n",
    "\n",
    "# 사용자 입력\n",
    "input_messages = [HumanMessage(content=\"내 취미가 뭐였더라...\")]\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, {\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단기 메모리를 위한 쓰레드 ID 제공(thread_id)\n",
    "# 장기 메모리를 위한 사용자 ID 제공(user_id)\n",
    "config = {\"configurable\": {\"thread_id\": \"3\", \"user_id\": \"teddy\"}}\n",
    "\n",
    "# 사용자 입력\n",
    "input_messages = [HumanMessage(content=\"내 취미가 뭐였더라...\")]\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, {\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistant_memory.get((\"memories\", \"teddy\"), \"user_memory\").value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단기 메모리를 위한 쓰레드 ID 제공(thread_id)\n",
    "# 장기 메모리를 위한 사용자 ID 제공(user_id)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"john\"}}\n",
    "\n",
    "# 사용자 입력\n",
    "input_messages = [HumanMessage(content=\"안녕 반가워! 혹시 내 취미 기억해?\")]\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, {\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단기 메모리를 위한 쓰레드 ID 제공(thread_id)\n",
    "# 장기 메모리를 위한 사용자 ID 제공(user_id)\n",
    "config = {\"configurable\": {\"thread_id\": \"3\", \"user_id\": \"teddy\"}}\n",
    "\n",
    "# 사용자 입력\n",
    "input_messages = [HumanMessage(content=\"나에 대해 아는 정보 모두 말해줘\")]\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, {\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추적: https://smith.langchain.com/public/618341ed-4bc2-443f-8ad0-f96fc464fac8/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
